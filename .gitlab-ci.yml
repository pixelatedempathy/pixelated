# GitLab CI/CD Pipeline for Pixelated Empathy
# Enterprise-grade CI/CD with intelligent orchestration, security scanning, and zero-downtime deployments

spec:
  inputs:
    # Runtime versions
    node_version:
      type: string
      default: "24"
      description: "Node.js version to use for builds and tests"
    pnpm_version:
      type: string
      default: "10.23.0"
      description: "pnpm version to use for package management"
    python_version:
      type: string
      default: "3.11"
      description: "Python version to use for Python-based jobs"
    
    # GCP Configuration
    gcp_project_id:
      type: string
      default: "pixelated-463209-e5"
      description: "Google Cloud Platform project ID"
    gcp_region:
      type: string
      default: "us-east1"
      description: "GCP region for deployments and services"
    
    # Artifact Registry Configuration
    ar_repo:
      type: string
      default: "pixel-front"
      description: "Artifact Registry repository name"
    ar_image_name:
      type: string
      default: "pixel-front-web"
      description: "Artifact Registry image name"
    
    # Environment URLs
    staging_url:
      type: string
      default: "https://staging.pixelatedempathy.tech"
      description: "Staging environment URL"
    production_url:
      type: string
      default: "https://pixelatedempathy.tech"
      description: "Production environment URL"
    
    # Deployment Configuration
    deployment_timeout:
      type: string
      default: "600s"
      description: "Timeout for deployment operations"
    health_check_timeout:
      type: string
      default: "300"
      description: "Timeout for health check operations"
    
    # Cache Configuration
    cache_version:
      type: string
      default: "v1"
      description: "Cache version for cache invalidation"
    
    # Security Configuration
    trivy_timeout:
      type: string
      default: "10m"
      description: "Timeout for Trivy security scans"
    
    # Deployment Strategy
    deployment_strategy:
      type: string
      default: "rolling"
      options: ["rolling", "blue-green", "canary"]
      description: "Deployment strategy to use"
    
    # Replica Configuration
    replicas:
      type: number
      default: 3
      description: "Number of replicas for deployments"
    
    # Canary Configuration
    canary_percentage:
      type: number
      default: 25
      description: "Percentage of traffic for canary deployments"
    rollback_threshold:
      type: number
      default: 5
      description: "Error threshold for automatic rollback"
    
    # Rolling Deployment Configuration
    max_surge:
      type: number
      default: 1
      description: "Maximum surge pods for rolling deployments"
    max_unavailable:
      type: number
      default: 0
      description: "Maximum unavailable pods for rolling deployments"
    
    # Kubernetes Configuration
    gke_cluster_name:
      type: string
      default: ""
      description: "GKE cluster name (required for deployments)"
    gke_zone:
      type: string
      default: ""
      description: "GKE cluster zone (required for deployments)"
    kube_namespace_staging:
      type: string
      default: "pixelated-staging"
      description: "Kubernetes namespace for staging deployments"
    kube_namespace_production:
      type: string
      default: "pixelated-production"
      description: "Kubernetes namespace for production deployments"
---

stages:
  - validate
  - build
  - security
  - deploy
  - health-check
  - cleanup

variables:
  NODE_VERSION: $[[ inputs.node_version ]]
  PNPM_VERSION: $[[ inputs.pnpm_version ]]
  PYTHON_VERSION: $[[ inputs.python_version ]]
  REGISTRY: $CI_REGISTRY
  IMAGE_NAME: $CI_REGISTRY_IMAGE
  GCP_PROJECT_ID: $[[ inputs.gcp_project_id ]]
  GCP_REGION: $[[ inputs.gcp_region ]]
  AR_REPO: $[[ inputs.ar_repo ]]
  AR_IMAGE_NAME: $[[ inputs.ar_image_name ]]
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"
  # GitLab-specific variables
  GIT_DEPTH: 0
  GIT_STRATEGY: fetch
  # Cache configuration
  CACHE_VERSION: $[[ inputs.cache_version ]]
  PNPM_CACHE_DIR: "$CI_PROJECT_DIR/.pnpm-store"
  NODE_CACHE_DIR: "$CI_PROJECT_DIR/node_modules"
  # Security scanning
  TRIVY_CACHE_DIR: "$CI_PROJECT_DIR/.trivy-cache"
  TRIVY_TIMEOUT: $[[ inputs.trivy_timeout ]]
  # Deployment configuration
  DEPLOYMENT_TIMEOUT: $[[ inputs.deployment_timeout ]]
  HEALTH_CHECK_TIMEOUT: $[[ inputs.health_check_timeout ]]
  # Environment URLs
  STAGING_URL: $[[ inputs.staging_url ]]
  PRODUCTION_URL: $[[ inputs.production_url ]]
  # Kubernetes Configuration
  GKE_CLUSTER_NAME: $[[ inputs.gke_cluster_name ]]
  GKE_ZONE: $[[ inputs.gke_zone ]]
  KUBE_NAMESPACE_STAGING: $[[ inputs.kube_namespace_staging ]]
  KUBE_NAMESPACE_PRODUCTION: $[[ inputs.kube_namespace_production ]]

# Cache configuration for faster builds
cache:
  key: "${CI_COMMIT_REF_SLUG}-${CACHE_VERSION}"
  paths:
    - .pnpm-store/
    - node_modules/
    - .trivy-cache/
  policy: pull-push

# Validation stage - fast parallel validation (template)
.validate:
  stage: validate
  image: node:${NODE_VERSION}-slim
  before_script:
    - apt-get update -qq && apt-get install -y -qq git curl > /dev/null
    - corepack enable pnpm
    - pnpm config set store-dir $PNPM_CACHE_DIR
    - pnpm --version
    - mkdir -p $PNPM_CACHE_DIR
    - pnpm install --frozen-lockfile || echo "‚ö†Ô∏è Dependencies already cached"
  script:
    - echo "üîç Running validation..."
  parallel:
    matrix:
      - VALIDATION_TYPE: [dependencies, lint, typecheck]

validate:dependencies:
  extends: .validate
  script:
    - echo "üîç Running dependency validation..."
    - pnpm audit --audit-level moderate || echo "‚ö†Ô∏è Audit warnings found but continuing"
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_BRANCH =~ /^feature\/.*/

validate:lint:
  extends: .validate
  script:
    - echo "üîç Running lint validation..."
    - pnpm lint:ci || echo "‚ö†Ô∏è Linting completed with warnings"
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_BRANCH =~ /^feature\/.*/

validate:typecheck:
  extends: .validate
  script:
    - echo "üîç Running typecheck validation..."
    - pnpm typecheck || echo "‚ö†Ô∏è Type checking completed with warnings"
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_BRANCH =~ /^feature\/.*/

# Build stage - build application and container image
build:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  needs: ["validate:dependencies", "validate:lint", "validate:typecheck"]
  variables:
    DOCKER_BUILDKIT: 1
    BUILDKIT_PROGRESS: plain
  before_script:
    - echo "üèóÔ∏è Setting up build environment..."
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - echo "üèóÔ∏è Building application with progressive memory optimization..."
    
    # Build Node.js application in container
    - docker build --target builder -t ${IMAGE_NAME}:builder-${CI_COMMIT_SHORT_SHA} .
    
    # Build final runtime image
    - docker build 
      --build-arg SENTRY_RELEASE=${CI_COMMIT_SHORT_SHA}
      --build-arg SENTRY_DSN=${SENTRY_DSN}
      --build-arg SENTRY_AUTH_TOKEN=${SENTRY_AUTH_TOKEN}
      --build-arg PUBLIC_SENTRY_DSN=${PUBLIC_SENTRY_DSN}
      -t ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} .
    
    # Tag with additional labels
    - docker tag ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} ${IMAGE_NAME}:latest
    - docker tag ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} ${IMAGE_NAME}:${CI_COMMIT_REF_NAME}
    
    # Push all tags
    - docker push ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
    - docker push ${IMAGE_NAME}:latest
    - docker push ${IMAGE_NAME}:${CI_COMMIT_REF_NAME}
    
    # Save image digest for security scanning
    - docker inspect ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} --format='{{.Id}}' > image-digest.txt
    - echo "IMAGE_DIGEST=$(cat image-digest.txt)" >> build.env
    - echo "IMAGE_TAG=${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}" >> build.env
    
    - echo "‚úÖ Build completed successfully"
  artifacts:
    reports:
      dotenv: build.env
    expire_in: 1 week
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_BRANCH =~ /^feature\/.*/

# Security scanning stage
security-scan:
  stage: security
  image: aquasec/trivy:latest
  services:
    - docker:dind
  needs: ["build"]
  variables:
    TRIVY_CACHE_DIR: $CI_PROJECT_DIR/.trivy-cache
  before_script:
    - echo "üîí Setting up security scanning..."
    - mkdir -p $TRIVY_CACHE_DIR
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script: |
    echo "üîí Running security scans..."

    # Pull the built image
    docker pull "${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"

    # Run Trivy vulnerability scan
    trivy image \
      --scanners vuln \
      --severity CRITICAL,HIGH \
      --format sarif \
      --output trivy-results.sarif \
      --cache-dir "$TRIVY_CACHE_DIR" \
      --timeout "$TRIVY_TIMEOUT" \
      "${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"

    # Check for critical vulnerabilities
    trivy image \
      --scanners vuln \
      --severity CRITICAL \
      --exit-code 1 \
      --cache-dir "$TRIVY_CACHE_DIR" \
      --timeout "$TRIVY_TIMEOUT" \
      "${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}" || echo "‚ö†Ô∏è Critical vulnerabilities found"

    # Container security configuration check
    echo "üîç Checking container security configuration..."
    USER_ID=$(docker inspect "${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}" --format='{{.Config.User}}' 2>/dev/null || echo "")
    if [ -z "$USER_ID" ] || [ "$USER_ID" = "root" ] || [ "$USER_ID" = "0" ]; then
      echo "‚ö†Ô∏è Container may run as root - checking runtime behavior"
      RUNTIME_USER=$(timeout 30 docker run --rm "${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}" whoami 2>/dev/null || echo "unknown")
      if [ "$RUNTIME_USER" = "root" ]; then
        echo "‚ùå Container runs as root - security risk"
        exit 1
      else
        echo "‚úÖ Container runs as non-root user at runtime: $RUNTIME_USER"
      fi
    else
      echo "‚úÖ Container configured with non-root user: $USER_ID"
    fi

    # Check exposed ports
    EXPOSED_PORTS=$(docker inspect "${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}" --format='{{range $p, $conf := .Config.ExposedPorts}}{{$p}} {{end}}' 2>/dev/null || echo "")
    echo "‚ÑπÔ∏è Exposed ports: ${EXPOSED_PORTS:-none}"

    echo "‚úÖ Security scanning completed"
  artifacts:
    reports:
      sast: trivy-results.sarif
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_BRANCH =~ /^feature\/.*/

# Sentry release creation
sentry-release:
  stage: security
  image: node:${NODE_VERSION}-slim
  needs: ["build"]
  before_script:
    - apt-get update -qq && apt-get install -y -qq curl > /dev/null
    - corepack enable pnpm
  script: |
    echo "üìä Creating Sentry release..."
    
    # Validate Sentry configuration
    if [ -z "${SENTRY_DSN:-}" ] && [ -z "${SENTRY_AUTH_TOKEN:-}" ]; then
      echo "‚ö†Ô∏è Sentry configuration not found, skipping release creation"
      exit 0
    fi
    
    # Install Sentry CLI
    curl -sL https://sentry.io/get-cli/ | sh || {
      echo "‚ùå Failed to install Sentry CLI"
      exit 1
    }
    
    # Create release
    sentry-cli releases new "${CI_COMMIT_SHORT_SHA}" || echo "‚ö†Ô∏è Release may already exist"
    
    # Upload sourcemaps if dist directory exists
    if [ -d "./dist" ] && [ -n "$(find ./dist -name '*.map' 2>/dev/null)" ]; then
      echo "üì¶ Uploading sourcemaps..."
      sentry-cli releases files "${CI_COMMIT_SHORT_SHA}" upload-sourcemaps ./dist \
        --rewrite --strip-prefix ./ --strip-common-prefix || echo "‚ö†Ô∏è Sourcemap upload failed"
    else
      echo "‚ÑπÔ∏è No sourcemaps found in ./dist, skipping upload"
    fi
    
    sentry-cli releases finalize "${CI_COMMIT_SHORT_SHA}" || echo "‚ö†Ô∏è Release finalization failed"
    
    echo "‚úÖ Sentry release created"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# Deployment stage with multiple strategies
.deploy:
  stage: deploy
  image: google/cloud-sdk:alpine
  needs: ["build", "security-scan"]
  before_script:
    - echo "üöÄ Setting up deployment environment..."
    - gcloud --version
    - kubectl version --client
  script:
    - echo "üöÄ Deploying to GKE..."
  environment:
    name: $ENVIRONMENT_NAME
    url: $ENVIRONMENT_URL
    on_stop: cleanup-deployment

# Rolling deployment
deploy:rolling:
  extends: .deploy
  variables:
    ENVIRONMENT_NAME: staging
    ENVIRONMENT_URL: $STAGING_URL
    KUBE_NAMESPACE: $KUBE_NAMESPACE_STAGING
    DEPLOYMENT_STRATEGY: "rolling"
    REPLICAS: $[[ inputs.replicas ]]
    MAX_SURGE: $[[ inputs.max_surge ]]
    MAX_UNAVAILABLE: $[[ inputs.max_unavailable ]]
  script: |
    set -euo pipefail
    echo "üöÄ Starting rolling deployment to GKE..."
    echo "Image: ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"
    echo "Deployment: pixelated"
    echo "Namespace: ${KUBE_NAMESPACE}"
    
    # Validate required variables
    if [ -z "${GCP_SERVICE_ACCOUNT_KEY:-}" ]; then
      echo "‚ùå GCP_SERVICE_ACCOUNT_KEY is required but not set"
      exit 1
    fi
    if [ -z "${GKE_CLUSTER_NAME:-}" ] || [ -z "${GKE_ZONE:-}" ]; then
      echo "‚ùå GKE_CLUSTER_NAME and GKE_ZONE are required but not set"
      exit 1
    fi

    # Authenticate to GKE
    echo "$GCP_SERVICE_ACCOUNT_KEY" > /tmp/gcp-key.json
    chmod 600 /tmp/gcp-key.json
    trap 'rm -f /tmp/gcp-key.json' EXIT
    gcloud auth activate-service-account --key-file /tmp/gcp-key.json
    gcloud config set project "$GCP_PROJECT_ID"
    gcloud container clusters get-credentials "$GKE_CLUSTER_NAME" --zone "$GKE_ZONE" --project "$GCP_PROJECT_ID"
    
    # Cleanup credentials
    rm -f /tmp/gcp-key.json

    # Apply Kubernetes manifests
    echo "üìã Applying Kubernetes manifests..."
    kubectl apply -f k8s/ -n "${KUBE_NAMESPACE}" || true

    # Update deployment with new image
    echo "üîÑ Updating deployment image..."
    kubectl set image deployment/pixelated app="${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}" -n "${KUBE_NAMESPACE}" || {
      echo "‚ùå Failed to update deployment image"
      exit 1
    }

    # Wait for rollout to complete
    echo "‚è≥ Waiting for rollout to complete..."
    kubectl rollout status deployment/pixelated -n "${KUBE_NAMESPACE}" --timeout="${DEPLOYMENT_TIMEOUT}" || {
      echo "‚ùå Deployment rollout failed"
      kubectl rollout undo deployment/pixelated -n "${KUBE_NAMESPACE}"
      exit 1
    }

    echo "‚úÖ Rolling deployment completed successfully"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# Blue-green deployment
deploy:blue-green:
  extends: .deploy
  variables:
    ENVIRONMENT_NAME: production
    ENVIRONMENT_URL: $PRODUCTION_URL
    KUBE_NAMESPACE: $KUBE_NAMESPACE_PRODUCTION
    DEPLOYMENT_STRATEGY: "blue-green"
    REPLICAS: $[[ inputs.replicas ]]
  script: |
    set -euo pipefail
    echo "üöÄ Starting blue-green deployment..."
    echo "Image: ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"
    echo "Namespace: ${KUBE_NAMESPACE}"
    
    # Validate required variables
    if [ -z "${GCP_SERVICE_ACCOUNT_KEY:-}" ]; then
      echo "‚ùå GCP_SERVICE_ACCOUNT_KEY is required but not set"
      exit 1
    fi
    if [ -z "${GKE_CLUSTER_NAME:-}" ] || [ -z "${GKE_ZONE:-}" ]; then
      echo "‚ùå GKE_CLUSTER_NAME and GKE_ZONE are required but not set"
      exit 1
    fi
    if [ ! -f "./scripts/deploy-blue-green.sh" ]; then
      echo "‚ùå deploy-blue-green.sh script not found"
      exit 1
    fi

    # Authenticate to GKE
    echo "$GCP_SERVICE_ACCOUNT_KEY" > /tmp/gcp-key.json
    chmod 600 /tmp/gcp-key.json
    trap 'rm -f /tmp/gcp-key.json' EXIT
    gcloud auth activate-service-account --key-file /tmp/gcp-key.json
    gcloud config set project "$GCP_PROJECT_ID"
    gcloud container clusters get-credentials "$GKE_CLUSTER_NAME" --zone "$GKE_ZONE" --project "$GCP_PROJECT_ID"
    
    # Cleanup credentials
    rm -f /tmp/gcp-key.json

    # Apply blue-green deployment
    echo "üìã Applying blue-green deployment..."
    . ./scripts/deploy-blue-green.sh || {
      echo "‚ùå Blue-green deployment failed"
      exit 1
    }

    echo "‚úÖ Blue-green deployment completed successfully"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: manual
    - if: $CI_COMMIT_TAG
      when: manual

# Canary deployment
deploy:canary:
  extends: .deploy
  variables:
    ENVIRONMENT_NAME: production
    ENVIRONMENT_URL: $PRODUCTION_URL
    KUBE_NAMESPACE: $KUBE_NAMESPACE_PRODUCTION
    DEPLOYMENT_STRATEGY: "canary"
    CANARY_PERCENTAGE: $[[ inputs.canary_percentage ]]
    ROLLBACK_THRESHOLD: $[[ inputs.rollback_threshold ]]
  script: |
    set -euo pipefail
    echo "üöÄ Starting canary deployment..."
    echo "Image: ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"
    echo "Canary percentage: ${CANARY_PERCENTAGE}%"
    echo "Namespace: ${KUBE_NAMESPACE}"
    
    # Validate required variables
    if [ -z "${GCP_SERVICE_ACCOUNT_KEY:-}" ]; then
      echo "‚ùå GCP_SERVICE_ACCOUNT_KEY is required but not set"
      exit 1
    fi
    if [ -z "${GKE_CLUSTER_NAME:-}" ] || [ -z "${GKE_ZONE:-}" ]; then
      echo "‚ùå GKE_CLUSTER_NAME and GKE_ZONE are required but not set"
      exit 1
    fi
    if [ ! -f "./scripts/deploy-canary.sh" ]; then
      echo "‚ùå deploy-canary.sh script not found"
      exit 1
    fi
    if [ "${CANARY_PERCENTAGE:-0}" -lt 1 ] || [ "${CANARY_PERCENTAGE:-0}" -gt 100 ]; then
      echo "‚ùå CANARY_PERCENTAGE must be between 1 and 100"
      exit 1
    fi

    # Authenticate to GKE
    echo "$GCP_SERVICE_ACCOUNT_KEY" > /tmp/gcp-key.json
    chmod 600 /tmp/gcp-key.json
    trap 'rm -f /tmp/gcp-key.json' EXIT
    gcloud auth activate-service-account --key-file /tmp/gcp-key.json
    gcloud config set project "$GCP_PROJECT_ID"
    gcloud container clusters get-credentials "$GKE_CLUSTER_NAME" --zone "$GKE_ZONE" --project "$GCP_PROJECT_ID"
    
    # Cleanup credentials
    rm -f /tmp/gcp-key.json

    # Apply canary deployment
    echo "üìã Applying canary deployment..."
    . ./scripts/deploy-canary.sh || {
      echo "‚ùå Canary deployment failed"
      exit 1
    }

    echo "‚úÖ Canary deployment completed successfully"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: manual
    - if: $CI_COMMIT_TAG
      when: manual

# Mirror primary GitLab image to Google Artifact Registry via Workload Identity Federation
mirror-to-artifact-registry:
  stage: deploy
  image: gcr.io/google.com/cloudsdktool/cloud-sdk:slim
  identity: google_cloud
  needs: ["build"]
  script:
    - |
      set -euo pipefail
      echo "üöÄ Mirroring image to Artifact Registry..."
      
      # Validate required variables
      if [ -z "${GOOGLE_APPLICATION_CREDENTIALS:-}" ]; then
        echo "‚ùå GOOGLE_APPLICATION_CREDENTIALS is required but not set"
        exit 1
      fi
      
      gcloud auth login --cred-file="${GOOGLE_APPLICATION_CREDENTIALS}" || {
        echo "‚ùå Failed to authenticate with GCP"
        exit 1
      }
      gcloud config set project "$GCP_PROJECT_ID"
      gcloud auth configure-docker "${GCP_REGION}-docker.pkg.dev" --quiet

      # Pull from primary GitLab registry
      echo "üì• Pulling image from GitLab registry..."
      docker pull "${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}" || {
        echo "‚ùå Failed to pull image from GitLab registry"
        exit 1
      }

      # Tag for Artifact Registry
      AR_IMAGE_TAG="${GCP_REGION}-docker.pkg.dev/${GCP_PROJECT_ID}/${AR_REPO}/${AR_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"
      echo "üè∑Ô∏è Tagging image as ${AR_IMAGE_TAG}..."
      docker tag "${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}" "${AR_IMAGE_TAG}"

      # Push to Artifact Registry mirror
      echo "üì§ Pushing image to Artifact Registry..."
      docker push "${AR_IMAGE_TAG}" || {
        echo "‚ùå Failed to push image to Artifact Registry"
        exit 1
      }
      
      echo "‚úÖ Image mirrored successfully"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# Optional Cloud Run test deployment using the mirrored Artifact Registry image
cloud-run-test-deploy:
  stage: deploy
  image: gcr.io/google.com/cloudsdktool/cloud-sdk:slim
  identity: google_cloud
  needs:
    - job: mirror-to-artifact-registry
  variables:
    CLOUD_RUN_SERVICE: "pixel-front-test"
  script:
    - |
      set -euo pipefail
      echo "üöÄ Deploying test service to Cloud Run..."
      
      if [ -z "${GOOGLE_APPLICATION_CREDENTIALS:-}" ]; then
        echo "‚ùå GOOGLE_APPLICATION_CREDENTIALS is required but not set"
        exit 1
      fi
      
      gcloud auth login --cred-file="${GOOGLE_APPLICATION_CREDENTIALS}" || {
        echo "‚ùå Failed to authenticate with GCP"
        exit 1
      }
      gcloud config set project "$GCP_PROJECT_ID"
      gcloud config set run/region "$GCP_REGION"
      
      AR_IMAGE_TAG="${GCP_REGION}-docker.pkg.dev/${GCP_PROJECT_ID}/${AR_REPO}/${AR_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"
      echo "üì¶ Deploying ${AR_IMAGE_TAG} to Cloud Run..."
      
      gcloud run deploy "$CLOUD_RUN_SERVICE" \
        --image="${AR_IMAGE_TAG}" \
        --platform=managed \
        --allow-unauthenticated \
        --region="$GCP_REGION" || {
        echo "‚ùå Cloud Run deployment failed"
        exit 1
      }
      
      echo "‚úÖ Cloud Run deployment completed"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: manual

# Optional GKE test deployment using the mirrored Artifact Registry image
gke-test-deploy:
  stage: deploy
  image: gcr.io/google.com/cloudsdktool/cloud-sdk:slim
  identity: google_cloud
  needs:
    - job: mirror-to-artifact-registry
  variables:
    GKE_TEST_CLUSTER_NAME: "pixelated-test"
    GKE_TEST_LOCATION: "us-east1"
    GKE_TEST_NAMESPACE: "pixelated-test"
  script:
    - |
      set -euo pipefail
      echo "üöÄ Deploying test workload to GKE..."
      
      if [ -z "${GOOGLE_APPLICATION_CREDENTIALS:-}" ]; then
        echo "‚ùå GOOGLE_APPLICATION_CREDENTIALS is required but not set"
        exit 1
      fi
      
      gcloud auth login --cred-file="${GOOGLE_APPLICATION_CREDENTIALS}" || {
        echo "‚ùå Failed to authenticate with GCP"
        exit 1
      }
      gcloud config set project "$GCP_PROJECT_ID"
      gcloud container clusters get-credentials "$GKE_TEST_CLUSTER_NAME" \
        --region "$GKE_TEST_LOCATION" \
        --project "$GCP_PROJECT_ID" || {
        echo "‚ùå Failed to get GKE credentials"
        exit 1
      }

      AR_IMAGE_TAG="${GCP_REGION}-docker.pkg.dev/${GCP_PROJECT_ID}/${AR_REPO}/${AR_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"
      
      # Simple rollout to test namespace using Artifact Registry image
      if kubectl -n "$GKE_TEST_NAMESPACE" get deployment pixelated >/dev/null 2>&1; then
        echo "üîÑ Updating existing deployment image..."
        kubectl -n "$GKE_TEST_NAMESPACE" set image deployment/pixelated \
          app="${AR_IMAGE_TAG}" || {
          echo "‚ùå Failed to update deployment"
          exit 1
        }
      else
        echo "üì¶ Creating new deployment..."
        kubectl -n "$GKE_TEST_NAMESPACE" create deployment pixelated \
          --image="${AR_IMAGE_TAG}" || {
          echo "‚ùå Failed to create deployment"
          exit 1
        }
      fi

      echo "‚è≥ Waiting for rollout to complete..."
      kubectl -n "$GKE_TEST_NAMESPACE" rollout status deployment/pixelated --timeout=300s || {
        echo "‚ùå Deployment rollout failed"
        kubectl -n "$GKE_TEST_NAMESPACE" rollout undo deployment/pixelated
        exit 1
      }
      
      echo "‚úÖ GKE test deployment completed"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: manual

# Health check stage
health-check:
  stage: health-check
  image: google/cloud-sdk:alpine
  needs: ["deploy:rolling"]
  variables:
    KUBE_NAMESPACE: $KUBE_NAMESPACE_STAGING
  script: |
    set -euo pipefail
    echo "üè• Running health checks..."
    
    # Validate required variables
    if [ -z "${GCP_SERVICE_ACCOUNT_KEY:-}" ]; then
      echo "‚ùå GCP_SERVICE_ACCOUNT_KEY is required but not set"
      exit 1
    fi
    if [ -z "${GKE_CLUSTER_NAME:-}" ] || [ -z "${GKE_ZONE:-}" ]; then
      echo "‚ùå GKE_CLUSTER_NAME and GKE_ZONE are required but not set"
      exit 1
    fi

    # Authenticate to GKE
    echo "$GCP_SERVICE_ACCOUNT_KEY" > /tmp/gcp-key.json
    chmod 600 /tmp/gcp-key.json
    trap 'rm -f /tmp/gcp-key.json' EXIT
    gcloud auth activate-service-account --key-file /tmp/gcp-key.json
    gcloud config set project "$GCP_PROJECT_ID"
    gcloud container clusters get-credentials "$GKE_CLUSTER_NAME" --zone "$GKE_ZONE" --project "$GCP_PROJECT_ID"
    
    # Cleanup credentials
    rm -f /tmp/gcp-key.json

    # Check deployment health
    echo "üìä Deployment status:"
    kubectl get deployment pixelated -n "${KUBE_NAMESPACE}" -o wide || {
      echo "‚ùå Deployment not found in namespace ${KUBE_NAMESPACE}"
      exit 1
    }

    # Check pod health
    echo "üîç Pod health:"
    kubectl get pods -l app=pixelated -n "${KUBE_NAMESPACE}" -o wide

    # Check service status
    echo "üåê Service status:"
    kubectl get service pixelated-service -n "${KUBE_NAMESPACE}" || echo "‚ö†Ô∏è Service not found"

    # Detailed health check
    READY_PODS=$(kubectl get pods -l app=pixelated -n "${KUBE_NAMESPACE}" -o json | jq '[.items[] | select(.status.phase == "Running" and (.status.containerStatuses[]?.ready // false))] | length' || echo "0")
    TOTAL_PODS=$(kubectl get pods -l app=pixelated -n "${KUBE_NAMESPACE}" -o json | jq '.items | length' || echo "0")
    echo "üìà Health summary: $READY_PODS/$TOTAL_PODS pods ready"

    if [ "$READY_PODS" -eq 0 ]; then
      echo "‚ùå No healthy pods found"
      kubectl describe pods -l app=pixelated -n "${KUBE_NAMESPACE}"
      exit 1
    elif [ "$READY_PODS" -lt "$TOTAL_PODS" ]; then
      echo "‚ö†Ô∏è Some pods are not ready"
      kubectl describe pods -l app=pixelated -n "${KUBE_NAMESPACE}" | grep -A 10 -B 5 "Warning\|Error" || true
    else
      echo "‚úÖ All pods are healthy"
    fi

    # Test internal connectivity if possible
    if [ -n "${STAGING_URL:-}" ]; then
      echo "üåê Testing external connectivity..."
      if curl -f --connect-timeout 10 --max-time 30 "${STAGING_URL}/api/health" >/dev/null 2>&1; then
        echo "‚úÖ External health check passed"
      else
        echo "‚ö†Ô∏è External health check failed (non-fatal)"
      fi
    fi

    echo "‚úÖ Health check completed"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# Cleanup stage
cleanup-deployment:
  stage: cleanup
  image: docker:latest
  services:
    - docker:dind
  variables:
    ENVIRONMENT_NAME: staging
  when: manual
  script:
    - |
      set -euo pipefail
      echo "üßπ Starting cleanup process..."
      echo "üìã Configuration:"
      echo "  - Keep last 3 images"
      echo "  - Cleanup images older than 12h"
      
      # Login to registry
      docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" "$CI_REGISTRY" || {
        echo "‚ùå Failed to login to registry"
        exit 1
      }
      
      # Get list of images sorted by creation date (newest first)
      # Note: This only works for local images, not registry images
      # For registry cleanup, use GitLab API or registry cleanup policies
      IMAGES=$(docker images --format "{{.Repository}}:{{.Tag}}\t{{.CreatedAt}}" 2>/dev/null | \
        grep "${IMAGE_NAME}" | \
        head -20 | \
        sort -k2 -r || echo "")
      
      if [ -z "$IMAGES" ]; then
        echo "‚ÑπÔ∏è No local images found for ${IMAGE_NAME}"
        echo "‚ÑπÔ∏è For registry cleanup, use GitLab Container Registry cleanup policies"
        exit 0
      fi
      
      IMAGE_COUNT=$(echo "$IMAGES" | wc -l)
      echo "üìä Found $IMAGE_COUNT local images for ${IMAGE_NAME}"
      
      if [ "$IMAGE_COUNT" -gt 3 ]; then
        # Remove images beyond the keep threshold
        IMAGES_TO_REMOVE=$(echo "$IMAGES" | tail -n +4 | awk '{print $1}')
        echo "$IMAGES_TO_REMOVE" | while read -r image; do
          if [ -n "$image" ]; then
            echo "üóëÔ∏è Removing $image..."
            docker rmi "$image" || echo "‚ö†Ô∏è Could not remove $image (may be in use)"
          fi
        done
        echo "‚úÖ Cleanup completed"
      else
        echo "‚úÖ Image count within retention policy"
      fi
      
      echo "üìä Cleanup completed successfully"
  environment:
    name: $ENVIRONMENT_NAME
    action: stop

# Performance testing
performance-test:
  stage: health-check
  image: node:${NODE_VERSION}-slim
  needs: ["deploy:rolling"]
  script:
    - echo "üìà Running performance tests..."
    - corepack enable pnpm
    - pnpm install --frozen-lockfile
    - pnpm run performance:test
    - echo "‚úÖ Performance tests completed"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# E2E testing
e2e-test:
  stage: health-check
  image: mcr.microsoft.com/playwright:v1.56.1-jammy
  needs: ["deploy:rolling"]
  variables:
    PLAYWRIGHT_BROWSERS_PATH: 0
    PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD: 1
  script:
    - echo "üé≠ Running E2E tests..."
    - corepack enable pnpm
    - pnpm install --frozen-lockfile
    - pnpm run e2e:smoke
    - echo "‚úÖ E2E tests completed"
  artifacts:
    reports:
      junit: test-results/junit.xml
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# Include additional pipeline configurations
include:
  - local: .gitlab/ci/security.yml
  - local: .gitlab/ci/compliance.yml
  - local: .gitlab/ci/monitoring.yml
  - local: .gitlab/ci/environments.yml