#!/usr/bin/env python3
"""
Metadata Enrichment and Validation System - Task 5.5.3.2 Part 2

Advanced metadata enrichment and validation capabilities:
- Automated metadata extraction and enrichment
- Content analysis and classification
- Metadata validation and consistency checking
- Cross-reference validation with external sources
- Metadata standardization and normalization
- Bulk metadata operations and updates
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Set, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timezone
from collections import Counter, defaultdict
import hashlib

# Enterprise imports
import sys
sys.path.append(str(Path(__file__).parent.parent / "enterprise_config"))
from enterprise_config import get_config
from enterprise_logging import get_logger
from enterprise_error_handling import handle_error, with_retry

from conversation_provenance_tracker import ConversationMetadata, ConversationProvenanceTracker, ProvenanceEventType

@dataclass
class MetadataEnrichmentRule:
    """Rule for automated metadata enrichment."""
    rule_id: str
    rule_name: str
    description: str
    field_target: str
    condition: Dict[str, Any]
    action: Dict[str, Any]
    priority: int = 1
    enabled: bool = True

@dataclass
class ValidationRule:
    """Metadata validation rule."""
    rule_id: str
    rule_name: str
    description: str
    field: str
    validation_type: str  # required, format, range, enum, custom
    parameters: Dict[str, Any]
    severity: str = "error"  # error, warning, info
    enabled: bool = True

@dataclass
class MetadataValidationResult:
    """Result of metadata validation."""
    conversation_id: str
    is_valid: bool
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    info_messages: List[str] = field(default_factory=list)
    validation_timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    rules_applied: List[str] = field(default_factory=list)

class ContentAnalyzer:
    """Analyzes conversation content for metadata extraction."""
    
    def __init__(self):
        self.logger = get_logger("content_analyzer")
        
        # Therapeutic technique patterns
        self.technique_patterns = {
            'cognitive_behavioral_therapy': [
                r'\b(thought.*pattern|cognitive.*distortion|reframe|challenge.*thought)\b',
                r'\b(CBT|cognitive.*behav|thought.*record)\b'
            ],
            'mindfulness': [
                r'\b(mindful|present.*moment|breathing.*exercise|meditation)\b',
                r'\b(awareness|observe.*thought|ground.*yourself)\b'
            ],
            'exposure_therapy': [
                r'\b(gradual.*exposure|face.*fear|systematic.*desensitization)\b',
                r'\b(exposure.*hierarchy|confront.*anxiety)\b'
            ],
            'acceptance_commitment_therapy': [
                r'\b(ACT|accept.*commit|psychological.*flexibility)\b',
                r'\b(values.*based|defusion|acceptance)\b'
            ],
            'dialectical_behavior_therapy': [
                r'\b(DBT|dialectical|distress.*tolerance|emotion.*regulation)\b',
                r'\b(wise.*mind|interpersonal.*effectiveness)\b'
            ]
        }
        
        # Content warning patterns
        self.warning_patterns = {
            'suicide_ideation': [
                r'\b(suicid|kill.*myself|end.*life|not.*worth.*living)\b',
                r'\b(better.*off.*dead|harm.*myself)\b'
            ],
            'self_harm': [
                r'\b(cut.*myself|self.*harm|hurt.*myself)\b',
                r'\b(cutting|burning.*myself|self.*injur)\b'
            ],
            'substance_abuse': [
                r'\b(drinking.*problem|drug.*use|addiction|substance.*abuse)\b',
                r'\b(overdose|withdrawal|rehab)\b'
            ],
            'domestic_violence': [
                r'\b(domestic.*violence|abusive.*relationship|partner.*hits)\b',
                r'\b(physical.*abuse|emotional.*abuse)\b'
            ],
            'trauma': [
                r'\b(trauma|PTSD|flashback|nightmare)\b',
                r'\b(assault|abuse|violence|accident)\b'
            ]
        }
        
        # Category patterns
        self.category_patterns = {
            'anxiety_disorders': [
                r'\b(anxiety|panic|phobia|worry|nervous)\b',
                r'\b(anxious|panic.*attack|social.*anxiety)\b'
            ],
            'depression': [
                r'\b(depress|sad|hopeless|worthless)\b',
                r'\b(low.*mood|no.*energy|sleep.*problem)\b'
            ],
            'relationship_issues': [
                r'\b(relationship|marriage|partner|spouse)\b',
                r'\b(communication|conflict|divorce|breakup)\b'
            ],
            'work_stress': [
                r'\b(work.*stress|job.*pressure|workplace|career)\b',
                r'\b(boss|colleague|deadline|burnout)\b'
            ],
            'family_issues': [
                r'\b(family|parent|child|sibling)\b',
                r'\b(mother|father|son|daughter|family.*conflict)\b'
            ]
        }
    
    def analyze_content(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze conversation content for metadata extraction."""
        
        # Combine all message content
        full_text = ""
        for message in messages:
            if isinstance(message, dict):
                content = message.get('content', '')
                if not content:
                    # Handle old format
                    for key, value in message.items():
                        if key not in ['role', 'turn_id']:
                            content += str(value) + " "
                full_text += content.lower() + " "
        
        analysis_result = {
            'therapeutic_techniques': self._detect_therapeutic_techniques(full_text),
            'content_warnings': self._detect_content_warnings(full_text),
            'categories': self._detect_categories(full_text),
            'sentiment_indicators': self._analyze_sentiment_indicators(full_text),
            'complexity_metrics': self._calculate_complexity_metrics(full_text),
            'language_features': self._analyze_language_features(messages)
        }
        
        return analysis_result
    
    def _detect_therapeutic_techniques(self, text: str) -> List[str]:
        """Detect therapeutic techniques mentioned in text."""
        detected_techniques = []
        
        for technique, patterns in self.technique_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    detected_techniques.append(technique)
                    break
        
        return detected_techniques
    
    def _detect_content_warnings(self, text: str) -> List[str]:
        """Detect content that may require warnings."""
        warnings = []
        
        for warning_type, patterns in self.warning_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    warnings.append(warning_type)
                    break
        
        return warnings
    
    def _detect_categories(self, text: str) -> List[str]:
        """Detect conversation categories based on content."""
        categories = []
        
        for category, patterns in self.category_patterns.items():
            score = 0
            for pattern in patterns:
                matches = len(re.findall(pattern, text, re.IGNORECASE))
                score += matches
            
            if score >= 2:  # Threshold for category assignment
                categories.append(category)
        
        return categories
    
    def _analyze_sentiment_indicators(self, text: str) -> Dict[str, int]:
        """Analyze sentiment indicators in text."""
        positive_words = ['good', 'better', 'happy', 'hope', 'positive', 'improve', 'progress', 'success']
        negative_words = ['bad', 'worse', 'sad', 'hopeless', 'negative', 'problem', 'difficult', 'struggle']
        
        positive_count = sum(len(re.findall(rf'\b{word}\b', text, re.IGNORECASE)) for word in positive_words)
        negative_count = sum(len(re.findall(rf'\b{word}\b', text, re.IGNORECASE)) for word in negative_words)
        
        return {
            'positive_indicators': positive_count,
            'negative_indicators': negative_count,
            'sentiment_ratio': positive_count / max(negative_count, 1)
        }
    
    def _calculate_complexity_metrics(self, text: str) -> Dict[str, float]:
        """Calculate text complexity metrics."""
        words = text.split()
        sentences = re.split(r'[.!?]+', text)
        
        if not words:
            return {'avg_word_length': 0, 'avg_sentence_length': 0, 'vocabulary_diversity': 0}
        
        avg_word_length = sum(len(word) for word in words) / len(words)
        avg_sentence_length = len(words) / max(len([s for s in sentences if s.strip()]), 1)
        vocabulary_diversity = len(set(words)) / len(words)
        
        return {
            'avg_word_length': avg_word_length,
            'avg_sentence_length': avg_sentence_length,
            'vocabulary_diversity': vocabulary_diversity
        }
    
    def _analyze_language_features(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze language features in conversation."""
        features = {
            'question_count': 0,
            'exclamation_count': 0,
            'avg_message_length': 0,
            'turn_taking_balance': 0
        }
        
        user_messages = 0
        assistant_messages = 0
        total_length = 0
        
        for message in messages:
            if isinstance(message, dict):
                content = message.get('content', '')
                if not content:
                    # Handle old format
                    for key, value in message.items():
                        if key not in ['role', 'turn_id']:
                            content += str(value) + " "
                
                features['question_count'] += content.count('?')
                features['exclamation_count'] += content.count('!')
                total_length += len(content.split())
                
                role = message.get('role', '')
                if role in ['user', 'human', 'client']:
                    user_messages += 1
                elif role in ['assistant', 'therapist', 'ai']:
                    assistant_messages += 1
        
        if messages:
            features['avg_message_length'] = total_length / len(messages)
        
        if user_messages + assistant_messages > 0:
            features['turn_taking_balance'] = min(user_messages, assistant_messages) / max(user_messages, assistant_messages)
        
        return features

class MetadataEnrichmentSystem:
    """System for automated metadata enrichment and validation."""
    
    def __init__(self, provenance_tracker: ConversationProvenanceTracker = None):
        self.config = get_config()
        self.logger = get_logger("metadata_enrichment")
        self.provenance_tracker = provenance_tracker
        self.content_analyzer = ContentAnalyzer()
        
        # Initialize enrichment rules
        self.enrichment_rules = self._create_default_enrichment_rules()
        
        # Initialize validation rules
        self.validation_rules = self._create_default_validation_rules()
        
        self.logger.info("Metadata enrichment system initialized")
    
    def _create_default_enrichment_rules(self) -> List[MetadataEnrichmentRule]:
        """Create default metadata enrichment rules."""
        return [
            MetadataEnrichmentRule(
                rule_id="auto_categorize_anxiety",
                rule_name="Auto-categorize anxiety conversations",
                description="Automatically add anxiety category based on content analysis",
                field_target="categories",
                condition={"content_analysis.categories": {"contains": "anxiety_disorders"}},
                action={"add_to_list": "anxiety"},
                priority=1
            ),
            MetadataEnrichmentRule(
                rule_id="auto_tag_techniques",
                rule_name="Auto-tag therapeutic techniques",
                description="Automatically add technique tags based on content analysis",
                field_target="therapeutic_techniques",
                condition={"content_analysis.therapeutic_techniques": {"not_empty": True}},
                action={"copy_from": "content_analysis.therapeutic_techniques"},
                priority=1
            ),
            MetadataEnrichmentRule(
                rule_id="quality_tier_from_score",
                rule_name="Calculate quality tier from score",
                description="Automatically calculate quality tier based on quality score",
                field_target="quality_tier",
                condition={"quality_score": {"exists": True}},
                action={"calculate": "quality_tier_from_score"},
                priority=2
            ),
            MetadataEnrichmentRule(
                rule_id="add_content_warnings",
                rule_name="Add content warnings",
                description="Add content warnings based on content analysis",
                field_target="content_warnings",
                condition={"content_analysis.content_warnings": {"not_empty": True}},
                action={"copy_from": "content_analysis.content_warnings"},
                priority=1
            )
        ]
    
    def _create_default_validation_rules(self) -> List[ValidationRule]:
        """Create default metadata validation rules."""
        return [
            ValidationRule(
                rule_id="conversation_id_required",
                rule_name="Conversation ID required",
                description="Conversation ID must be present and valid UUID",
                field="conversation_id",
                validation_type="required",
                parameters={},
                severity="error"
            ),
            ValidationRule(
                rule_id="quality_score_range",
                rule_name="Quality score range validation",
                description="Quality score must be between 0.0 and 1.0",
                field="quality_score",
                validation_type="range",
                parameters={"min": 0.0, "max": 1.0},
                severity="error"
            ),
            ValidationRule(
                rule_id="language_code_format",
                rule_name="Language code format",
                description="Language must be valid ISO 639-1 code",
                field="language",
                validation_type="enum",
                parameters={"allowed_values": ["en", "es", "fr", "de", "it", "pt", "zh", "ja", "ko"]},
                severity="warning"
            ),
            ValidationRule(
                rule_id="turn_count_positive",
                rule_name="Turn count must be positive",
                description="Turn count must be greater than 0",
                field="turn_count",
                validation_type="range",
                parameters={"min": 1},
                severity="error"
            ),
            ValidationRule(
                rule_id="quality_tier_valid",
                rule_name="Quality tier validation",
                description="Quality tier must be between 1 and 5",
                field="quality_tier",
                validation_type="range",
                parameters={"min": 1, "max": 5},
                severity="error"
            )
        ]
    
    def enrich_conversation_metadata(self, conversation_id: str, 
                                   conversation_data: Dict[str, Any],
                                   existing_metadata: ConversationMetadata = None) -> ConversationMetadata:
        """Enrich conversation metadata using automated analysis."""
        
        self.logger.info(f"Enriching metadata for conversation {conversation_id}")
        
        # Perform content analysis
        messages = conversation_data.get('messages', conversation_data.get('conversations', []))
        content_analysis = self.content_analyzer.analyze_content(messages)
        
        # Start with existing metadata or create new
        if existing_metadata:
            metadata = existing_metadata
        else:
            # Create basic metadata structure
            metadata = ConversationMetadata(
                conversation_id=conversation_id,
                original_id=conversation_data.get('original_id'),
                source_dataset=conversation_data.get('source_dataset', 'unknown'),
                source_type=conversation_data.get('source_type', 'original'),
                created_at=datetime.now(timezone.utc),
                last_modified=datetime.now(timezone.utc),
                title=conversation_data.get('title'),
                summary=conversation_data.get('summary'),
                language=conversation_data.get('language', 'en'),
                turn_count=len(messages),
                word_count=0,
                character_count=0,
                quality_score=conversation_data.get('quality_score', 0.0),
                quality_tier=1,
                quality_assessment_date=datetime.now(timezone.utc),
                quality_assessor="automated_system",
                processing_version="1.0",
                processing_pipeline=['import'],
                tags=conversation_data.get('tags', []),
                categories=conversation_data.get('categories', []),
                therapeutic_techniques=conversation_data.get('therapeutic_techniques', [])
            )
        
        # Apply enrichment rules
        enrichment_context = {
            'conversation_data': conversation_data,
            'content_analysis': content_analysis,
            'existing_metadata': metadata
        }
        
        applied_rules = []
        for rule in sorted(self.enrichment_rules, key=lambda r: r.priority):
            if rule.enabled and self._evaluate_condition(rule.condition, enrichment_context):
                self._apply_enrichment_action(rule, metadata, enrichment_context)
                applied_rules.append(rule.rule_id)
        
        # Update word and character counts
        total_words = 0
        total_chars = 0
        for message in messages:
            if isinstance(message, dict):
                content = message.get('content', '')
                if not content:
                    # Handle old format
                    for key, value in message.items():
                        if key not in ['role', 'turn_id']:
                            content += str(value) + " "
                
                words = len(content.split())
                total_words += words
                total_chars += len(content)
        
        metadata.word_count = total_words
        metadata.character_count = total_chars
        
        # Update checksum
        content_str = json.dumps(messages, sort_keys=True, ensure_ascii=False)
        metadata.checksum = hashlib.sha256(content_str.encode('utf-8')).hexdigest()
        
        # Record enrichment event
        if self.provenance_tracker:
            self.provenance_tracker.record_provenance_event(
                conversation_id=conversation_id,
                event_type=ProvenanceEventType.PROCESSED,
                actor="metadata_enrichment_system",
                description="Metadata enriched using automated analysis",
                metadata={
                    'enrichment_rules_applied': applied_rules,
                    'content_analysis_results': content_analysis
                }
            )
        
        self.logger.info(f"Enriched metadata for conversation {conversation_id} using {len(applied_rules)} rules")
        return metadata
    
    def validate_metadata(self, metadata: ConversationMetadata) -> MetadataValidationResult:
        """Validate conversation metadata against defined rules."""
        
        result = MetadataValidationResult(
            conversation_id=metadata.conversation_id,
            is_valid=True
        )
        
        metadata_dict = metadata.__dict__
        
        for rule in self.validation_rules:
            if not rule.enabled:
                continue
            
            result.rules_applied.append(rule.rule_id)
            validation_passed, message = self._apply_validation_rule(rule, metadata_dict)
            
            if not validation_passed:
                if rule.severity == "error":
                    result.errors.append(f"{rule.rule_name}: {message}")
                    result.is_valid = False
                elif rule.severity == "warning":
                    result.warnings.append(f"{rule.rule_name}: {message}")
                elif rule.severity == "info":
                    result.info_messages.append(f"{rule.rule_name}: {message}")
        
        # Record validation event
        if self.provenance_tracker:
            self.provenance_tracker.record_provenance_event(
                conversation_id=metadata.conversation_id,
                event_type=ProvenanceEventType.VALIDATED,
                actor="metadata_validation_system",
                description=f"Metadata validation {'passed' if result.is_valid else 'failed'}",
                metadata={
                    'validation_result': result.is_valid,
                    'error_count': len(result.errors),
                    'warning_count': len(result.warnings),
                    'rules_applied': result.rules_applied
                }
            )
        
        return result
    
    def _evaluate_condition(self, condition: Dict[str, Any], context: Dict[str, Any]) -> bool:
        """Evaluate enrichment rule condition."""
        
        for field_path, criteria in condition.items():
            value = self._get_nested_value(context, field_path)
            
            if isinstance(criteria, dict):
                for operator, expected in criteria.items():
                    if operator == "contains" and isinstance(value, list):
                        if expected not in value:
                            return False
                    elif operator == "not_empty":
                        if not value or (isinstance(value, list) and len(value) == 0):
                            return False
                    elif operator == "exists":
                        if value is None:
                            return False
                    elif operator == "equals":
                        if value != expected:
                            return False
            else:
                if value != criteria:
                    return False
        
        return True
    
    def _apply_enrichment_action(self, rule: MetadataEnrichmentRule, 
                                metadata: ConversationMetadata, 
                                context: Dict[str, Any]) -> None:
        """Apply enrichment rule action."""
        
        action = rule.action
        target_field = rule.field_target
        
        if "add_to_list" in action:
            value_to_add = action["add_to_list"]
            current_list = getattr(metadata, target_field, [])
            if isinstance(current_list, list) and value_to_add not in current_list:
                current_list.append(value_to_add)
                setattr(metadata, target_field, current_list)
        
        elif "copy_from" in action:
            source_path = action["copy_from"]
            source_value = self._get_nested_value(context, source_path)
            if source_value:
                if isinstance(source_value, list):
                    current_list = getattr(metadata, target_field, [])
                    if isinstance(current_list, list):
                        # Merge lists, avoiding duplicates
                        for item in source_value:
                            if item not in current_list:
                                current_list.append(item)
                        setattr(metadata, target_field, current_list)
                else:
                    setattr(metadata, target_field, source_value)
        
        elif "calculate" in action:
            calculation = action["calculate"]
            if calculation == "quality_tier_from_score":
                quality_score = metadata.quality_score
                if quality_score >= 0.9:
                    tier = 5
                elif quality_score >= 0.8:
                    tier = 4
                elif quality_score >= 0.7:
                    tier = 3
                elif quality_score >= 0.5:
                    tier = 2
                else:
                    tier = 1
                setattr(metadata, target_field, tier)
    
    def _apply_validation_rule(self, rule: ValidationRule, metadata_dict: Dict[str, Any]) -> Tuple[bool, str]:
        """Apply validation rule and return result."""
        
        field_value = metadata_dict.get(rule.field)
        
        if rule.validation_type == "required":
            if field_value is None or field_value == "":
                return False, f"Field '{rule.field}' is required but missing"
        
        elif rule.validation_type == "range":
            if field_value is not None:
                min_val = rule.parameters.get("min")
                max_val = rule.parameters.get("max")
                
                if min_val is not None and field_value < min_val:
                    return False, f"Field '{rule.field}' value {field_value} is below minimum {min_val}"
                
                if max_val is not None and field_value > max_val:
                    return False, f"Field '{rule.field}' value {field_value} is above maximum {max_val}"
        
        elif rule.validation_type == "enum":
            if field_value is not None:
                allowed_values = rule.parameters.get("allowed_values", [])
                if field_value not in allowed_values:
                    return False, f"Field '{rule.field}' value '{field_value}' not in allowed values: {allowed_values}"
        
        elif rule.validation_type == "format":
            if field_value is not None:
                pattern = rule.parameters.get("pattern")
                if pattern and not re.match(pattern, str(field_value)):
                    return False, f"Field '{rule.field}' value '{field_value}' does not match required format"
        
        return True, "Validation passed"
    
    def _get_nested_value(self, data: Dict[str, Any], path: str) -> Any:
        """Get nested value from dictionary using dot notation."""
        keys = path.split('.')
        current = data
        
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return None
        
        return current
    
    def bulk_enrich_metadata(self, conversations: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Perform bulk metadata enrichment on multiple conversations."""
        
        results = {
            'processed': 0,
            'enriched': 0,
            'errors': 0,
            'enrichment_summary': defaultdict(int)
        }
        
        for conversation_data in conversations:
            try:
                conversation_id = conversation_data.get('conversation_id')
                if not conversation_id:
                    results['errors'] += 1
                    continue
                
                enriched_metadata = self.enrich_conversation_metadata(
                    conversation_id=conversation_id,
                    conversation_data=conversation_data
                )
                
                results['processed'] += 1
                results['enriched'] += 1
                
                # Track enrichment statistics
                results['enrichment_summary']['total_tags'] += len(enriched_metadata.tags)
                results['enrichment_summary']['total_categories'] += len(enriched_metadata.categories)
                results['enrichment_summary']['total_techniques'] += len(enriched_metadata.therapeutic_techniques)
                
            except Exception as e:
                self.logger.error(f"Error enriching metadata for conversation: {e}")
                results['errors'] += 1
        
        return results

def main():
    """Test metadata enrichment and validation system."""
    print("üîç METADATA ENRICHMENT SYSTEM - Task 5.5.3.2 Part 2")
    print("=" * 60)
    
    # Initialize systems
    provenance_tracker = ConversationProvenanceTracker()
    enrichment_system = MetadataEnrichmentSystem(provenance_tracker)
    
    # Test with sample conversation
    sample_conversation = {
        'conversation_id': 'test-conv-002',
        'messages': [
            {'role': 'user', 'content': 'I have been feeling very anxious about my upcoming presentation at work. I keep having panic attacks and negative thoughts.'},
            {'role': 'assistant', 'content': 'I understand your anxiety about the presentation. Let\'s work on some cognitive behavioral therapy techniques to help you reframe those negative thoughts and manage your panic symptoms.'}
        ],
        'quality_score': 0.87,
        'source_dataset': 'professional_psychology',
        'language': 'en'
    }
    
    # Test content analysis
    print("üìä Analyzing conversation content...")
    content_analysis = enrichment_system.content_analyzer.analyze_content(sample_conversation['messages'])
    
    print(f"‚úÖ Content analysis completed:")
    print(f"   Therapeutic techniques: {content_analysis['therapeutic_techniques']}")
    print(f"   Categories: {content_analysis['categories']}")
    print(f"   Content warnings: {content_analysis['content_warnings']}")
    print(f"   Sentiment ratio: {content_analysis['sentiment_indicators']['sentiment_ratio']:.2f}")
    
    # Test metadata enrichment
    print("\nüîß Enriching conversation metadata...")
    enriched_metadata = enrichment_system.enrich_conversation_metadata(
        conversation_id=sample_conversation['conversation_id'],
        conversation_data=sample_conversation
    )
    
    print(f"‚úÖ Metadata enrichment completed:")
    print(f"   Quality tier: {enriched_metadata.quality_tier}")
    print(f"   Categories: {enriched_metadata.categories}")
    print(f"   Therapeutic techniques: {enriched_metadata.therapeutic_techniques}")
    print(f"   Word count: {enriched_metadata.word_count}")
    print(f"   Content warnings: {enriched_metadata.content_warnings}")
    
    # Test metadata validation
    print("\n‚úÖ Validating enriched metadata...")
    validation_result = enrichment_system.validate_metadata(enriched_metadata)
    
    print(f"‚úÖ Validation completed:")
    print(f"   Is valid: {validation_result.is_valid}")
    print(f"   Errors: {len(validation_result.errors)}")
    print(f"   Warnings: {len(validation_result.warnings)}")
    print(f"   Rules applied: {len(validation_result.rules_applied)}")
    
    if validation_result.errors:
        print("   Validation errors:")
        for error in validation_result.errors:
            print(f"     - {error}")
    
    if validation_result.warnings:
        print("   Validation warnings:")
        for warning in validation_result.warnings:
            print(f"     - {warning}")
    
    print(f"\n‚úÖ Metadata enrichment and validation system implemented!")
    print("‚úÖ Automated content analysis and classification")
    print("‚úÖ Rule-based metadata enrichment")
    print("‚úÖ Comprehensive metadata validation")
    print("‚úÖ Therapeutic technique detection")
    print("‚úÖ Content warning identification")
    print("‚úÖ Category auto-assignment")
    print("‚úÖ Bulk processing capabilities")

if __name__ == "__main__":
    main()
