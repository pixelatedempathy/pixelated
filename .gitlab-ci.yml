# GitLab CI/CD Pipeline for Pixelated Empathy
# Enterprise-grade CI/CD with intelligent orchestration, security scanning, and zero-downtime deployments

stages:
  - validate
  - build
  - security
  - deploy
  - health-check
  - cleanup

variables:
  NODE_VERSION: "24"
  PNPM_VERSION: "10.22.0"
  PYTHON_VERSION: "3.11"
  REGISTRY: $CI_REGISTRY
  IMAGE_NAME: $CI_REGISTRY_IMAGE
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"
  # GitLab-specific variables
  GIT_DEPTH: 0
  GIT_STRATEGY: fetch
  # Cache configuration
  CACHE_VERSION: "v1"
  PNPM_CACHE_DIR: "$CI_PROJECT_DIR/.pnpm-store"
  NODE_CACHE_DIR: "$CI_PROJECT_DIR/node_modules"
  # Security scanning
  TRIVY_CACHE_DIR: "$CI_PROJECT_DIR/.trivy-cache"
  TRIVY_TIMEOUT: "10m"
  # Deployment configuration
  DEPLOYMENT_TIMEOUT: "600s"
  HEALTH_CHECK_TIMEOUT: "300"
  # Environment URLs
  STAGING_URL: "https://staging.pixelatedempathy.tech"
  PRODUCTION_URL: "https://pixelatedempathy.tech"

# Cache configuration for faster builds
cache:
  key: "${CI_COMMIT_REF_SLUG}-${CACHE_VERSION}"
  paths:
    - .pnpm-store/
    - node_modules/
    - .trivy-cache/
  policy: pull-push

# Validation stage - fast parallel validation
.validate:
  stage: validate
  image: node:${NODE_VERSION}-slim
  before_script:
    - apt-get update -qq && apt-get install -y -qq git curl > /dev/null
    - corepack enable pnpm
    - pnpm config set store-dir $PNPM_CACHE_DIR
    - pnpm --version
  script:
    - echo "üîç Running validation..."
  parallel:
    matrix:
      - VALIDATION_TYPE: [dependencies, lint, typecheck]

validate:dependencies:
  extends: .validate
  script:
    - echo "üîç Running dependency validation..."
    - pnpm audit --audit-level moderate || echo "‚ö†Ô∏è Audit warnings found but continuing"
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_BRANCH =~ /^feature\/.*/

validate:lint:
  extends: .validate
  script:
    - echo "üîç Running lint validation..."
    - pnpm lint:ci || echo "‚ö†Ô∏è Linting completed with warnings"
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_BRANCH =~ /^feature\/.*/

validate:typecheck:
  extends: .validate
  script:
    - echo "üîç Running typecheck validation..."
    - pnpm typecheck || echo "‚ö†Ô∏è Type checking completed with warnings"
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_BRANCH =~ /^feature\/.*/

# Build stage - build application and container image
build:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  needs: ["validate:dependencies", "validate:lint", "validate:typecheck"]
  variables:
    DOCKER_BUILDKIT: 1
    BUILDKIT_PROGRESS: plain
  before_script:
    - echo "üèóÔ∏è Setting up build environment..."
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - echo "üèóÔ∏è Building application with progressive memory optimization..."
    
    # Build Node.js application in container
    - docker build --target builder -t ${IMAGE_NAME}:builder-${CI_COMMIT_SHORT_SHA} .
    
    # Build final runtime image
    - docker build 
      --build-arg SENTRY_RELEASE=${CI_COMMIT_SHORT_SHA}
      --build-arg SENTRY_DSN=${SENTRY_DSN}
      --build-arg SENTRY_AUTH_TOKEN=${SENTRY_AUTH_TOKEN}
      --build-arg PUBLIC_SENTRY_DSN=${PUBLIC_SENTRY_DSN}
      -t ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} .
    
    # Tag with additional labels
    - docker tag ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} ${IMAGE_NAME}:latest
    - docker tag ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} ${IMAGE_NAME}:${CI_COMMIT_REF_NAME}
    
    # Push all tags
    - docker push ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
    - docker push ${IMAGE_NAME}:latest
    - docker push ${IMAGE_NAME}:${CI_COMMIT_REF_NAME}
    
    # Save image digest for security scanning
    - docker inspect ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} --format='{{.Id}}' > image-digest.txt
    - echo "IMAGE_DIGEST=$(cat image-digest.txt)" >> build.env
    - echo "IMAGE_TAG=${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}" >> build.env
    
    - echo "‚úÖ Build completed successfully"
  artifacts:
    reports:
      dotenv: build.env
    expire_in: 1 week
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_BRANCH =~ /^feature\/.*/

# Security scanning stage
security-scan:
  stage: security
  image: aquasec/trivy:latest
  services:
    - docker:dind
  needs: ["build"]
  variables:
    TRIVY_CACHE_DIR: $CI_PROJECT_DIR/.trivy-cache
    TRIVY_TIMEOUT: 10m
  before_script:
    - echo "üîí Setting up security scanning..."
    - mkdir -p $TRIVY_CACHE_DIR
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - echo "üîí Running security scans..."
    
    # Pull the built image
    - docker pull ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
    
    # Run Trivy vulnerability scan
    - trivy image 
      --scanners vuln
      --severity CRITICAL,HIGH
      --format sarif
      --output trivy-results.sarif
      --cache-dir $TRIVY_CACHE_DIR
      --timeout $TRIVY_TIMEOUT
      ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
    
    # Check for critical vulnerabilities
    - trivy image 
      --scanners vuln
      --severity CRITICAL
      --exit-code 1
      --cache-dir $TRIVY_CACHE_DIR
      --timeout $TRIVY_TIMEOUT
      ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} || echo "‚ö†Ô∏è Critical vulnerabilities found"
    
    # Container security configuration check
    - echo "üîç Checking container security configuration..."
    - USER_ID=$(docker inspect ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} --format='{{.Config.User}}' 2>/dev/null || echo "")
    - |
      if [ -z "$USER_ID" ] || [ "$USER_ID" = "root" ] || [ "$USER_ID" = "0" ]; then
        echo "‚ö†Ô∏è Container may run as root - checking runtime behavior";
        RUNTIME_USER=$(timeout 30 docker run --rm ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} whoami 2>/dev/null || echo "unknown");
        if [ "$RUNTIME_USER" = "root" ]; then
          echo "‚ùå Container runs as root - security risk";
          exit 1;
        else
          echo "‚úÖ Container runs as non-root user at runtime: $RUNTIME_USER";
        fi;
      else
        echo "‚úÖ Container configured with non-root user: $USER_ID";
      fi
    
    # Check exposed ports
    - EXPOSED_PORTS=$(docker inspect ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} --format='{{range $p, $conf := .Config.ExposedPorts}}{{$p}} {{end}}' 2>/dev/null || echo "")
    - echo "‚ÑπÔ∏è Exposed ports: ${EXPOSED_PORTS:-none}"
    
    - echo "‚úÖ Security scanning completed"
  artifacts:
    reports:
      sast: trivy-results.sarif
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_BRANCH =~ /^feature\/.*/

# Sentry release creation
sentry-release:
  stage: security
  image: node:${NODE_VERSION}-slim
  needs: ["build"]
  before_script:
    - apt-get update -qq && apt-get install -y -qq curl > /dev/null
    - corepack enable pnpm
  script:
    - echo "üìä Creating Sentry release..."
    
    # Install Sentry CLI
    - curl -sL https://sentry.io/get-cli/ | sh
    
    # Create release
    - sentry-cli releases new "${CI_COMMIT_SHORT_SHA}" || true
    - sentry-cli releases files "${CI_COMMIT_SHORT_SHA}" upload-sourcemaps ./dist --rewrite --strip-prefix ./ --strip-common-prefix || true
    - sentry-cli releases finalize "${CI_COMMIT_SHORT_SHA}" || true
    
    - echo "‚úÖ Sentry release created"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# Deployment stage with multiple strategies
.deploy:
  stage: deploy
  image: google/cloud-sdk:alpine
  needs: ["build", "security-scan"]
  before_script:
    - echo "üöÄ Setting up deployment environment..."
    - gcloud --version
    - kubectl version --client
  script:
    - echo "üöÄ Deploying to GKE..."
  environment:
    name: $ENVIRONMENT_NAME
    url: $ENVIRONMENT_URL
    on_stop: cleanup-deployment

# Rolling deployment
deploy:rolling:
  extends: .deploy
  variables:
    ENVIRONMENT_NAME: staging
    ENVIRONMENT_URL: $STAGING_URL
    KUBE_NAMESPACE: "pixelated-staging"
    DEPLOYMENT_STRATEGY: rolling
    REPLICAS: "3"
    MAX_SURGE: "1"
    MAX_UNAVAILABLE: "0"
  script:
    - echo "üöÄ Starting rolling deployment to GKE..."
    - echo "Image: ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"
    - echo "Deployment: pixelated"
    - echo "Namespace: ${KUBE_NAMESPACE}"
    
    # Authenticate to GKE
    - echo $GCP_SERVICE_ACCOUNT_KEY > /tmp/gcp-key.json
    - gcloud auth activate-service-account --key-file /tmp/gcp-key.json
    - gcloud config set project $GCP_PROJECT_ID
    - gcloud container clusters get-credentials $GKE_CLUSTER_NAME --zone $GKE_ZONE --project $GCP_PROJECT_ID
    
    # Apply Kubernetes manifests
    - echo "üìã Applying Kubernetes manifests..."
    - kubectl apply -f k8s/ -n ${KUBE_NAMESPACE} || true
    
    # Update deployment with new image
    - echo "üîÑ Updating deployment image..."
    - kubectl set image deployment/pixelated app=${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} -n ${KUBE_NAMESPACE}
    
    # Wait for rollout to complete
    - echo "‚è≥ Waiting for rollout to complete..."
    - kubectl rollout status deployment/pixelated -n ${KUBE_NAMESPACE} --timeout=${DEPLOYMENT_TIMEOUT}
    
    - echo "‚úÖ Rolling deployment completed successfully"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# Blue-green deployment
deploy:blue-green:
  extends: .deploy
  variables:
    ENVIRONMENT_NAME: production
    ENVIRONMENT_URL: $PRODUCTION_URL
    DEPLOYMENT_STRATEGY: blue-green
    REPLICAS: "3"
  script:
    - echo "üöÄ Starting blue-green deployment..."
    - echo "Image: ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"
    
    # Authenticate to GKE
    - echo $GCP_SERVICE_ACCOUNT_KEY > /tmp/gcp-key.json
    - gcloud auth activate-service-account --key-file /tmp/gcp-key.json
    - gcloud config set project $GCP_PROJECT_ID
    - gcloud container clusters get-credentials $GKE_CLUSTER_NAME --zone $GKE_ZONE --project $GCP_PROJECT_ID
    
    # Apply blue-green deployment
    - echo "üìã Applying blue-green deployment..."
    - . ./scripts/deploy-blue-green.sh
    
    - echo "‚úÖ Blue-green deployment completed successfully"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: manual
    - if: $CI_COMMIT_TAG
      when: manual

# Canary deployment
deploy:canary:
  extends: .deploy
  variables:
    ENVIRONMENT_NAME: production
    ENVIRONMENT_URL: $PRODUCTION_URL
    DEPLOYMENT_STRATEGY: canary
    CANARY_PERCENTAGE: "25"
    ROLLBACK_THRESHOLD: "5"
  script:
    - echo "üöÄ Starting canary deployment..."
    - echo "Image: ${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"
    - echo "Canary percentage: ${CANARY_PERCENTAGE}%"
    
    # Authenticate to GKE
    - echo $GCP_SERVICE_ACCOUNT_KEY > /tmp/gcp-key.json
    - gcloud auth activate-service-account --key-file /tmp/gcp-key.json
    - gcloud config set project $GCP_PROJECT_ID
    - gcloud container clusters get-credentials $GKE_CLUSTER_NAME --zone $GKE_ZONE --project $GCP_PROJECT_ID
    
    # Apply canary deployment
    - echo "üìã Applying canary deployment..."
    - . ./scripts/deploy-canary.sh
    
    - echo "‚úÖ Canary deployment completed successfully"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: manual
    - if: $CI_COMMIT_TAG
      when: manual

# Health check stage
health-check:
  stage: health-check
  image: google/cloud-sdk:alpine
  needs: ["deploy:rolling"]
  script:
    - echo "üè• Running health checks..."
    
    # Authenticate to GKE
    - echo $GCP_SERVICE_ACCOUNT_KEY > /tmp/gcp-key.json
    - gcloud auth activate-service-account --key-file /tmp/gcp-key.json
    - gcloud config set project $GCP_PROJECT_ID
    - gcloud container clusters get-credentials $GKE_CLUSTER_NAME --zone $GKE_ZONE --project $GCP_PROJECT_ID
    
    # Check deployment health
    - echo "üìä Deployment status:"
    - kubectl get deployment pixelated -o wide
    
    # Check pod health
    - echo "üîç Pod health:"
    - kubectl get pods -l app=pixelated -o wide
    
    # Check service status
    - echo "üåê Service status:"
    - kubectl get service pixelated-service
    
    # Detailed health check
    - READY_PODS=$(kubectl get pods -l app=pixelated -o json | jq '[.items[] | select(.status.phase == "Running" and (.status.containerStatuses[]?.ready // false))] | length')
    - TOTAL_PODS=$(kubectl get pods -l app=pixelated -o json | jq '.items | length')
    - echo "üìà Health summary: $READY_PODS/$TOTAL_PODS pods ready"
    
    - |
      if [ "$READY_PODS" -eq 0 ]; then
        echo "‚ùå No healthy pods found"
        kubectl describe pods -l app=pixelated
        exit 1
      elif [ "$READY_PODS" -lt "$TOTAL_PODS" ]; then
        echo "‚ö†Ô∏è Some pods are not ready"
        kubectl describe pods -l app=pixelated | grep -A 10 -B 5 "Warning\|Error" || true
      else
        echo "‚úÖ All pods are healthy"
      fi
    
    # Test internal connectivity if possible
    - |
      if [ -n "$STAGING_URL" ]; then
        echo "üåê Testing external connectivity..."
        if curl -f --connect-timeout 10 --max-time 30 "$STAGING_URL/api/health" >/dev/null 2>&1; then
          echo "‚úÖ External health check passed"
        else
          echo "‚ö†Ô∏è External health check failed"
        fi
      fi
    
    - echo "‚úÖ Health check completed"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# Cleanup stage
cleanup-deployment:
  stage: cleanup
  image: docker:latest
  services:
    - docker:dind
  variables:
    ENVIRONMENT_NAME: staging
  when: manual
  script:
    - echo "üßπ Starting cleanup process..."
    - echo "üìã Configuration:"
    - echo "  - Keep last 3 images"
    - echo "  - Cleanup images older than 12h"
    
    # Login to registry
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    
    # Get list of images sorted by creation date (newest first)
    - IMAGES=$(docker images --format "{{.Repository}}:{{.Tag}}\t{{.CreatedAt}}" | \
        grep ${IMAGE_NAME} | \
        head -20 | \
        sort -k2 -r)
    
    - IMAGE_COUNT=$(echo "$IMAGES" | wc -l)
    - echo "üìä Found $IMAGE_COUNT images for ${IMAGE_NAME}"
    
    - |
      if [ $IMAGE_COUNT -gt 3 ]; then
        # Remove images beyond the keep threshold
        IMAGES_TO_REMOVE=$(echo "$IMAGES" | tail -n +4 | awk '{print $1}')
        echo "$IMAGES_TO_REMOVE" | while read -r image; do
          echo "üóëÔ∏è Removing $image..."
          docker rmi "$image" || echo "‚ö†Ô∏è Could not remove $image"
        done
        echo "‚úÖ Cleanup completed"
      else
        echo "‚úÖ Image count within retention policy"
      fi
    
    - echo "üìä Cleanup completed successfully"
  environment:
    name: $ENVIRONMENT_NAME
    action: stop

# Performance testing
performance-test:
  stage: health-check
  image: node:${NODE_VERSION}-slim
  needs: ["deploy:rolling"]
  script:
    - echo "üìà Running performance tests..."
    - corepack enable pnpm
    - pnpm install --frozen-lockfile
    - pnpm run performance:test
    - echo "‚úÖ Performance tests completed"
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# E2E testing
e2e-test:
  stage: health-check
  image: mcr.microsoft.com/playwright:v1.56.1-jammy
  needs: ["deploy:rolling"]
  variables:
    PLAYWRIGHT_BROWSERS_PATH: 0
    PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD: 1
  script:
    - echo "üé≠ Running E2E tests..."
    - corepack enable pnpm
    - pnpm install --frozen-lockfile
    - pnpm run e2e:smoke
    - echo "‚úÖ E2E tests completed"
  artifacts:
    reports:
      junit: test-results/junit.xml
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# Include additional pipeline configurations
include:
  - local: .gitlab/ci/security.yml
  - local: .gitlab/ci/compliance.yml
  - local: .gitlab/ci/monitoring.yml
  - local: .gitlab/ci/environments.yml