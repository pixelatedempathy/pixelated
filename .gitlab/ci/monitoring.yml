# Monitoring and observability pipeline configuration
# Real-time metrics, alerting, and performance monitoring

.monitoring-base:
  stage: health-check
  image: node:${NODE_VERSION}-slim
  before_script:
    - apt-get update -qq && apt-get install -y -qq curl jq > /dev/null
    - corepack enable pnpm

# Performance monitoring
monitoring:performance:
  extends: .monitoring-base
  needs: ["deploy:rolling"]
  script:
    - echo "ðŸ“ˆ Running performance monitoring..."
    
    # Wait for deployment to stabilize
    - echo "â³ Waiting for deployment to stabilize..."
    - sleep 30
    
    # Test application performance
    - echo "ðŸ” Testing application performance..."
    - PERFORMANCE_TEST_URL="${STAGING_URL:-http://localhost:4321}"
    
    # Response time testing
    - echo "â±ï¸ Testing response times..."
    - START_TIME=$(date +%s%N)
    - curl -s -o /dev/null -w "%{http_code},%{time_total},%{size_download}" "$PERFORMANCE_TEST_URL" > performance-metrics.csv
    - END_TIME=$(date +%s%N)
    - RESPONSE_TIME=$(( (END_TIME - START_TIME) / 1000000 ))
    - echo "Response time: ${RESPONSE_TIME}ms"
    
    # Memory usage monitoring
    - echo "ðŸ§  Monitoring memory usage..."
    - kubectl top pods -l app=pixelated --no-headers > memory-usage.txt || echo "âš ï¸ Could not get memory usage"
    
    # CPU usage monitoring
    - echo "âš¡ Monitoring CPU usage..."
    - kubectl top pods -l app=pixelated --no-headers > cpu-usage.txt || echo "âš ï¸ Could not get CPU usage"
    
    # Generate performance report
    - echo "ðŸ“Š Generating performance report..."
    - |
      jq -n \
        --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
        --arg commit_sha "${CI_COMMIT_SHORT_SHA}" \
        --arg pipeline_id "${CI_PIPELINE_ID}" \
        --argjson response_time_ms "${RESPONSE_TIME}" \
        --arg test_url "${PERFORMANCE_TEST_URL}" \
        --arg memory_usage "$(cat memory-usage.txt 2>/dev/null || echo 'N/A')" \
        --arg cpu_usage "$(cat cpu-usage.txt 2>/dev/null || echo 'N/A')" \
        '{timestamp: $timestamp, commit_sha: $commit_sha, pipeline_id: $pipeline_id, response_time_ms: $response_time_ms, test_url: $test_url, memory_usage: $memory_usage, cpu_usage: $cpu_usage, status: "monitored"}' > performance-report.json
    
    - echo "âœ… Performance monitoring completed"
  artifacts:
    reports:
      performance: performance-report.json
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# Health monitoring
monitoring:health:
  extends: .monitoring-base
  needs: ["deploy:rolling"]
  script:
    - echo "ðŸ¥ Running health monitoring..."
    
    # Application health check
    - echo "ðŸ” Checking application health..."
    - HEALTH_URL="${STAGING_URL:-http://localhost:4321}/api/health"
    - HEALTH_RESPONSE=$(curl -s -w "%{http_code}" -o /dev/null "$HEALTH_URL" || echo "000")
    - |
      if [ "$HEALTH_RESPONSE" = "200" ]; then
        echo "âœ… Application is healthy"
        HEALTH_STATUS="healthy"
      else
        echo "âŒ Application health check failed: $HEALTH_RESPONSE"
        HEALTH_STATUS="unhealthy"
      fi
    
    # Database health check
    - echo "ðŸ—„ï¸ Checking database health..."
    - DB_HEALTH_URL="${STAGING_URL:-http://localhost:4321}/api/health/db"
    - DB_HEALTH_RESPONSE=$(curl -s -w "%{http_code}" -o /dev/null "$DB_HEALTH_URL" || echo "000")
    - |
      if [ "$DB_HEALTH_RESPONSE" = "200" ]; then
        echo "âœ… Database is healthy"
        DB_HEALTH_STATUS="healthy"
      else
        echo "âŒ Database health check failed: $DB_HEALTH_RESPONSE"
        DB_HEALTH_STATUS="unhealthy"
      fi
    
    # Redis health check
    - echo "ðŸ”„ Checking Redis health..."
    - REDIS_HEALTH_URL="${STAGING_URL:-http://localhost:4321}/api/health/redis"
    - REDIS_HEALTH_RESPONSE=$(curl -s -w "%{http_code}" -o /dev/null "$REDIS_HEALTH_URL" || echo "000")
    - |
      if [ "$REDIS_HEALTH_RESPONSE" = "200" ]; then
        echo "âœ… Redis is healthy"
        REDIS_HEALTH_STATUS="healthy"
      else
        echo "âŒ Redis health check failed: $REDIS_HEALTH_RESPONSE"
        REDIS_HEALTH_STATUS="unhealthy"
      fi
    
    # Generate health report
    - echo "ðŸ“Š Generating health report..."
    - OVERALL_STATUS=$([ "$HEALTH_STATUS" = "healthy" ] && [ "$DB_HEALTH_STATUS" = "healthy" ] && [ "$REDIS_HEALTH_STATUS" = "healthy" ] && echo "healthy" || echo "degraded")
    - |
      jq -n \
        --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
        --arg commit_sha "${CI_COMMIT_SHORT_SHA}" \
        --arg pipeline_id "${CI_PIPELINE_ID}" \
        --arg application "${HEALTH_STATUS}" \
        --arg database "${DB_HEALTH_STATUS}" \
        --arg redis "${REDIS_HEALTH_STATUS}" \
        --arg overall_status "${OVERALL_STATUS}" \
        '{timestamp: $timestamp, commit_sha: $commit_sha, pipeline_id: $pipeline_id, health_checks: {application: $application, database: $database, redis: $redis}, overall_status: $overall_status}' > health-report.json
    
    - echo "âœ… Health monitoring completed"
  artifacts:
    reports:
      junit: test-results/health-junit.xml
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# Resource monitoring
monitoring:resources:
  extends: .monitoring-base
  needs: ["deploy:rolling"]
  variables:
    KUBE_NAMESPACE: "pixelated-staging"
  script:
    - echo "ðŸ“Š Running resource monitoring..."
    
    # Authenticate to GKE if needed
    - |
      if [ -n "$GCP_SERVICE_ACCOUNT_KEY" ]; then
        echo $GCP_SERVICE_ACCOUNT_KEY > /tmp/gcp-key.json
        gcloud auth activate-service-account --key-file /tmp/gcp-key.json
        gcloud config set project $GCP_PROJECT_ID
        gcloud container clusters get-credentials $GKE_CLUSTER_NAME --zone $GKE_ZONE --project $GCP_PROJECT_ID
      fi
    
    # Pod resource usage
    - echo "ðŸ“¦ Monitoring pod resources..."
    - kubectl top pods -l app=pixelated --no-headers > pod-resources.txt || echo "âš ï¸ Could not get pod resources"
    
    # Node resource usage
    - echo "ðŸ–¥ï¸ Monitoring node resources..."
    - kubectl top nodes --no-headers > node-resources.txt || echo "âš ï¸ Could not get node resources"
    
    # Disk usage
    - echo "ðŸ’¾ Monitoring disk usage..."
    - kubectl exec -n ${KUBE_NAMESPACE} $(kubectl get pods -n ${KUBE_NAMESPACE} -l app=pixelated -o jsonpath='{.items[0].metadata.name}') -- df -h > disk-usage.txt || echo "âš ï¸ Could not get disk usage"
    
    # Memory allocation
    - echo "ðŸ§  Monitoring memory allocation..."
    - kubectl exec -n ${KUBE_NAMESPACE} $(kubectl get pods -n ${KUBE_NAMESPACE} -l app=pixelated -o jsonpath='{.items[0].metadata.name}') -- free -h > memory-allocation.txt || echo "âš ï¸ Could not get memory allocation"
    
    # Generate resource report
    - echo "ðŸ“Š Generating resource report..."
    - |
      jq -n \
        --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
        --arg commit_sha "${CI_COMMIT_SHORT_SHA}" \
        --arg pipeline_id "${CI_PIPELINE_ID}" \
        --arg pod_resources "$(cat pod-resources.txt 2>/dev/null || echo 'N/A')" \
        --arg node_resources "$(cat node-resources.txt 2>/dev/null || echo 'N/A')" \
        --arg disk_usage "$(cat disk-usage.txt 2>/dev/null || echo 'N/A')" \
        --arg memory_allocation "$(cat memory-allocation.txt 2>/dev/null || echo 'N/A')" \
        '{timestamp: $timestamp, commit_sha: $commit_sha, pipeline_id: $pipeline_id, pod_resources: $pod_resources, node_resources: $node_resources, disk_usage: $disk_usage, memory_allocation: $memory_allocation, status: "monitored"}' > resource-report.json
    
    - echo "âœ… Resource monitoring completed"
  artifacts:
    reports:
      metrics: resource-report.json
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# Error rate monitoring
monitoring:errors:
  extends: .monitoring-base
  needs: ["deploy:rolling"]
  variables:
    KUBE_NAMESPACE: "pixelated-staging"
  script:
    - echo "ðŸš¨ Running error rate monitoring..."
    
    # Check application logs for errors
    - echo "ðŸ” Checking application logs..."
    - ERROR_COUNT=$(kubectl logs -n ${KUBE_NAMESPACE} -l app=pixelated --tail=1000 | grep -i "error\|exception\|fail" | wc -l)
    - echo "Found $ERROR_COUNT errors in recent logs"
    
    # Check for specific error patterns
    - echo "ðŸ” Checking for specific error patterns..."
    - DB_ERRORS=$(kubectl logs -n ${KUBE_NAMESPACE} -l app=pixelated --tail=1000 | grep -i "database\|connection\|timeout" | wc -l)
    - API_ERRORS=$(kubectl logs -n ${KUBE_NAMESPACE} -l app=pixelated --tail=1000 | grep -i "api\|request\|response" | wc -l)
    - AUTH_ERRORS=$(kubectl logs -n ${KUBE_NAMESPACE} -l app=pixelated --tail=1000 | grep -i "auth\|login\|token" | wc -l)
    
    - echo "Database errors: $DB_ERRORS"
    - echo "API errors: $API_ERRORS"
    - echo "Authentication errors: $AUTH_ERRORS"
    
    # Calculate error rate
    - TOTAL_LOGS=$(kubectl logs -n ${KUBE_NAMESPACE} -l app=pixelated --tail=1000 | wc -l)
    - |
      if [ "$TOTAL_LOGS" -eq 0 ]; then
        echo "âš ï¸ No logs found, cannot calculate error rate"
        ERROR_RATE=0
      else
        ERROR_RATE=$(( ERROR_COUNT * 100 / TOTAL_LOGS ))
      fi
    - echo "Error rate: ${ERROR_RATE}%"
    
    # Generate error report
    - echo "ðŸ“Š Generating error report..."
    - ERROR_STATUS=$([ $ERROR_RATE -lt 5 ] && echo "acceptable" || echo "high")
    - |
      jq -n \
        --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
        --arg commit_sha "${CI_COMMIT_SHORT_SHA}" \
        --arg pipeline_id "${CI_PIPELINE_ID}" \
        --argjson total_errors "${ERROR_COUNT}" \
        --argjson database_errors "${DB_ERRORS}" \
        --argjson api_errors "${API_ERRORS}" \
        --argjson auth_errors "${AUTH_ERRORS}" \
        --argjson error_rate_percent "${ERROR_RATE}" \
        --arg status "${ERROR_STATUS}" \
        '{timestamp: $timestamp, commit_sha: $commit_sha, pipeline_id: $pipeline_id, error_metrics: {total_errors: $total_errors, database_errors: $database_errors, api_errors: $api_errors, auth_errors: $auth_errors, error_rate_percent: $error_rate_percent}, status: $status}' > error-report.json
    
    # Alert if error rate is too high
    - |
      if [ $ERROR_RATE -gt 5 ]; then
        echo "âš ï¸ High error rate detected: ${ERROR_RATE}%"
      else
        echo "âœ… Error rate is acceptable: ${ERROR_RATE}%"
      fi
    
    - echo "âœ… Error rate monitoring completed"
  artifacts:
    reports:
      junit: test-results/errors-junit.xml
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# Alerting and notifications
monitoring:alerts:
  extends: .monitoring-base
  needs: ["monitoring:health", "monitoring:errors"]
  script:
    - echo "ðŸš¨ Setting up alerting and notifications..."
    
    # Check if any monitoring jobs failed
    - echo "ðŸ” Checking monitoring status..."
    - HEALTH_STATUS=$(cat health-report.json | jq -r '.overall_status' 2>/dev/null || echo "unknown")
    - ERROR_STATUS=$(cat error-report.json | jq -r '.status' 2>/dev/null || echo "unknown")
    
    # Generate alert if needed
    - |
      if [ "$HEALTH_STATUS" = "unhealthy" ] || [ "$ERROR_STATUS" = "high" ]; then
        echo "ðŸš¨ ALERT: System health issues detected"
        ALERT_LEVEL="critical"
        ALERT_MESSAGE="System health issues detected: Health=$HEALTH_STATUS, Error status=$ERROR_STATUS"
      else
        echo "âœ… System health is good"
        ALERT_LEVEL="info"
        ALERT_MESSAGE="System health monitoring completed successfully"
      fi
    
    # Create alert payload
    - |
      jq -n \
        --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
        --arg commit_sha "${CI_COMMIT_SHORT_SHA}" \
        --arg pipeline_id "${CI_PIPELINE_ID}" \
        --arg alert_level "${ALERT_LEVEL}" \
        --arg message "${ALERT_MESSAGE}" \
        --arg health_status "${HEALTH_STATUS}" \
        --arg error_status "${ERROR_STATUS}" \
        '{timestamp: $timestamp, commit_sha: $commit_sha, pipeline_id: $pipeline_id, alert_level: $alert_level, message: $message, health_status: $health_status, error_status: $error_status}' > alert-payload.json
    
    # Send alert (placeholder for actual alerting system)
    - echo "ðŸ“¤ Sending alert notification..."
    - echo "Alert level: $ALERT_LEVEL"
    - echo "Alert message: $ALERT_MESSAGE"
    
    # Here you would integrate with your alerting system
    # Examples: PagerDuty, Slack, Microsoft Teams, etc.
    - |
      if [ "$ALERT_LEVEL" = "critical" ]; then
        echo "ðŸš¨ Critical alert would be sent to operations team"
        # curl -X POST -H "Content-Type: application/json" -d @alert-payload.json $ALERT_WEBHOOK_URL
      fi
    
    - echo "âœ… Alerting and notifications completed"
  artifacts:
    reports:
      junit: test-results/alerts-junit.xml
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# Monitoring summary
monitoring:summary:
  extends: .monitoring-base
  needs: ["monitoring:performance", "monitoring:health", "monitoring:resources", "monitoring:errors", "monitoring:alerts"]
  script:
    - echo "ðŸ“Š Generating monitoring summary..."
    
    # Aggregate all monitoring reports
    - echo "ðŸ“‹ Aggregating monitoring reports..."
    - |
      jq -n \
        --arg summary_date "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
        --arg commit_sha "${CI_COMMIT_SHORT_SHA}" \
        --arg pipeline_id "${CI_PIPELINE_ID}" \
        --arg next_check "$(date -u -d '+5 minutes' +%Y-%m-%dT%H:%M:%SZ 2>/dev/null || date -u -v+5M +%Y-%m-%dT%H:%M:%SZ 2>/dev/null || echo 'N/A')" \
        '{summary_date: $summary_date, commit_sha: $commit_sha, pipeline_id: $pipeline_id, monitoring_areas: {performance: "monitored", health: "monitored", resources: "monitored", errors: "monitored", alerts: "configured"}, overall_status: "active", next_check: $next_check}' > monitoring-summary.json
    
    # Generate monitoring dashboard data
    - echo "ðŸ“Š Generating monitoring dashboard data..."
    - RESPONSE_TIME_VAL=$(cat performance-report.json 2>/dev/null | jq -r '.response_time_ms // "N/A"' || echo 'N/A')
    - ERROR_RATE_VAL=$(cat error-report.json 2>/dev/null | jq -r '.error_metrics.error_rate_percent // "N/A"' || echo 'N/A')
    - HEALTH_STATUS_VAL=$(cat health-report.json 2>/dev/null | jq -r '.overall_status // "N/A"' || echo 'N/A')
    - |
      jq -n \
        --arg updated "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
        --arg response_time "${RESPONSE_TIME_VAL}" \
        --arg error_rate "${ERROR_RATE_VAL}" \
        --arg health_status "${HEALTH_STATUS_VAL}" \
        --arg last_alert "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
        '{dashboard: {title: "Pixelated Empathy Monitoring", version: "1.0.0", updated: $updated, metrics: {response_time: $response_time, error_rate: $error_rate, health_status: $health_status, resource_usage: "monitored"}, alerts: {status: "configured", last_alert: $last_alert}}}' > monitoring-dashboard.json
    
    - echo "âœ… Monitoring summary generated"
    - echo "ðŸ“Š Overall monitoring status: ACTIVE"
  artifacts:
    reports:
      metrics: monitoring-summary.json
    expire_in: 1 month
    when: always
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG