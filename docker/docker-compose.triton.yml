
services:
  # Triton Inference Server with Pixel model
  triton-inference-server:
    build:
      context: .
      dockerfile: ai/triton/Dockerfile
    container_name: pixel-triton-server
    runtime: nvidia
    
    # GPU configuration
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - MODEL_REPOSITORY=/models
      - LOG_DIR=/workspace/logs
      - METRICS_PORT=8002
      - GRPC_PORT=8001
      - HTTP_PORT=8000
      - GPU_MEMORY_FRACTION=0.8
      - TRITON_PROFILE=development
    
    # Port mappings
    ports:
      - "8000:8000"  # HTTP
      - "8001:8001"  # gRPC
      - "8002:8002"  # Metrics
    
    # Volume mounts
    volumes:
      # Model repository (mount for development)
      - ./ai/triton/model_repository:/models:ro
      
      # Logs and outputs
      - ./logs/triton:/workspace/logs
      
      # Python client libraries
      - ./ai/triton/pixel_client.py:/workspace/pixel_client.py:ro
      - ./ai/triton/export_pixel_model.py:/workspace/export_pixel_model.py:ro
      
      # Scripts
      - ./ai/triton/scripts:/workspace/scripts:ro
    
    # Resource limits
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          cpus: '4'
          memory: 16G
    
    # Health check
    healthcheck:
      test: ["CMD", "bash", "/workspace/scripts/health_check.sh"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"
    
    # Network
    networks:
      - pixel-network
    
    # Restart policy
    restart: unless-stopped
    
    # Security
    cap_drop:
      - ALL
    cap_add:
      - SYS_NICE

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: pixel-prometheus
    
    environment:
      - TZ=UTC
    
    ports:
      - "9090:9090"
    
    volumes:
      - ./ai/triton/prometheus_config.yaml:/etc/prometheus/prometheus.yml:ro
      - ./logs/prometheus:/prometheus
    
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/usr/share/prometheus/console_libraries"
      - "--web.console.templates=/usr/share/prometheus/consoles"
    
    networks:
      - pixel-network
    
    depends_on:
      - triton-inference-server
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: pixel-grafana
    
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=pixelated_admin_2024
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    
    ports:
      - "3000:3000"
    
    volumes:
      - ./ai/triton/grafana_dashboard.yaml:/etc/grafana/provisioning/dashboards/pixel.yaml:ro
      - grafana_data:/var/lib/grafana
    
    networks:
      - pixel-network
    
    depends_on:
      - prometheus
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for caching and session management
  redis:
    image: redis:7-alpine
    container_name: pixel-redis
    
    ports:
      - "6379:6379"
    
    volumes:
      - redis_data:/data
    
    command:
      - "redis-server"
      - "--appendonly"
      - "yes"
      - "--maxmemory"
      - "2gb"
      - "--maxmemory-policy"
      - "allkeys-lru"
    
    networks:
      - pixel-network
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # PostgreSQL for metadata and results storage
  postgres:
    image: postgres:16-alpine
    container_name: pixel-postgres
    
    environment:
      - POSTGRES_DB=pixel_inference
      - POSTGRES_USER=pixel_user
      - POSTGRES_PASSWORD=pixel_password_secure_2024
    
    ports:
      - "5432:5432"
    
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./ai/triton/init_db.sql:/docker-entrypoint-initdb.d/init.sql:ro
    
    networks:
      - pixel-network
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U pixel_user -d pixel_inference"]
      interval: 10s
      timeout: 5s
      retries: 3

volumes:
  grafana_data:
  redis_data:
  postgres_data:

networks:
  pixel-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16
