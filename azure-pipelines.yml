trigger:
  branches:
    include:
    - main
    - master
    - develop
  paths:
    include:
    - src/**
    - infra/**
    - Dockerfile.azure
    - azure-pipelines.yml
    - package.json
    - pnpm-lock.yaml

pr:
  branches:
    include:
    - master
    - develop

variables:
- name: buildConfiguration
  value: Release
- name: nodeVersion
  value: 24.x
- name: dockerTag
  value: $(Build.BuildId)
- name: azureSubscription
  value: "pixelated-service-connection"
- name: resourceGroupName
  value: pixelated-rg
- name: appServiceName
  value: pixelated
- name: containerAppName
  value: pixelated-web
- name: containerRegistryPrefix
  value: pixelatedcr
- name: imageName
  value: pixelated-web
- name: azureLocation
  value: eastus
- name: environment
  value: production
- name: customDomain
  value: "pixelatedempathy.com"
- name: PYTHONWARNINGS
  value: "ignore::FutureWarning"

pool:
  name: Default
  demands:
  - agent.os -equals Linux
  - docker

stages:
- stage: Build
  displayName: Build Application
  jobs:
  - job: BuildApp
    displayName: Build Node.js Application
    pool:
      name: Default
    steps:
    - checkout: self
    - task: NodeTool@0
      displayName: Use Node.js $(nodeVersion)
      inputs:
        versionSpec: $(nodeVersion)

    - script: |
        npm install -g pnpm@10.15.0
        pnpm config set store-dir $(Agent.WorkFolder)/.pnpm-store
        mkdir -p $(Agent.WorkFolder)/.pnpm-store
      displayName: Install and configure pnpm

    - task: Cache@2
      displayName: Cache pnpm dependencies
      inputs:
        key: 'pnpm-v2 | "$(Agent.OS)" | pnpm-lock.yaml'
        restoreKeys: |
          pnpm-v2 | "$(Agent.OS)"
          pnpm | "$(Agent.OS)"
        path: $(Agent.WorkFolder)/.pnpm-store

    - script: |
        # Install dependencies with optimizations
        pnpm install --frozen-lockfile --prefer-offline
      displayName: Install dependencies

    - script: |
        # Install Node.js 24.x in container using nvm (no sudo)
        set -e
        export NVM_DIR="$HOME/.nvm"
        mkdir -p $NVM_DIR
        curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
        . $NVM_DIR/nvm.sh
        nvm install 24
        nvm use 24
        node --version
        which node
        echo "Node.js installation complete."
      displayName: "Install Node.js 24.x in container (pre-build)"

    - script: |
        # Ensure cache directories exist before cache task with robust path handling
        echo "Setting up cache directories for Astro build artifacts..."

        # Define cache directories with proper path handling
        CACHE_DIRS=(
          "node_modules/.astro"
          ".astro"
          "$(Agent.WorkFolder)/.astro-cache"
          "node_modules/.vite"
        )

        # Create cache directories with error handling
        for dir in "${CACHE_DIRS[@]}"; do
          # Clean the path and ensure it exists
          clean_dir=$(echo "$dir" | tr -d '\\n' | sed 's/\\\\n//g')
          echo "Creating cache directory: $clean_dir"
          mkdir -p "$clean_dir" || {
            echo "Warning: Failed to create $clean_dir, but continuing..."
          }

          # Verify directory was created
          if [ -d "$clean_dir" ]; then
            echo "‚úì Successfully created: $clean_dir"
            # Create a placeholder file to ensure directory is not empty
            touch "$clean_dir/.gitkeep" 2>/dev/null || true
          else
            echo "‚úó Failed to create: $clean_dir"
          fi
        done

        # Clean up any malformed cache files that might exist
        echo "Cleaning up potential malformed cache files..."
        for dir in "${CACHE_DIRS[@]}"; do
          clean_dir=$(echo "$dir" | tr -d '\\n' | sed 's/\\\\n//g')
          if [ -d "$clean_dir" ]; then
            find "$clean_dir" -name "*\\n*" -delete 2>/dev/null || true
          fi
        done

        # Final validation
        echo "Cache directory validation:"
        for dir in "${CACHE_DIRS[@]}"; do
          clean_dir=$(echo "$dir" | tr -d '\\n' | sed 's/\\\\n//g')
          if [ -d "$clean_dir" ]; then
            echo "‚úì $clean_dir exists and is accessible"
            ls -la "$clean_dir" 2>/dev/null | head -3 || echo "  (directory is empty or not listable)"
          else
            echo "‚úó $clean_dir does not exist"
          fi
        done

        echo "Cache directory setup completed"
      displayName: Prepare and validate cache directories
    - script: |
        echo "==== Cache Directory Diagnostics Before Cache@2 Step ===="
        echo "Current working directory: $(pwd)"
        for dir in node_modules/.astro .astro "$(Agent.WorkFolder)/.astro-cache" node_modules/.vite; do
          echo "Checking: $dir"
          if [ -d "$dir" ]; then
            ls -lna "$dir"
            stat "$dir"
            find "$dir" | head -20
          else
            echo "$dir does NOT exist"
          fi
        done
        echo "Listing parent directories for .astro-cache and .vite:"
        ls -lna "$(dirname "$(Agent.WorkFolder)/.astro-cache")"
        ls -lna "$(dirname "$(Build.SourcesDirectory)/node_modules/.vite")"
        echo "Full disk usage:"
        df -h
        echo "Current user: $(id)"
        echo "==== End Diagnostics ===="
      displayName: "Verbose diagnostics on Astro/Vite cache paths before Cache@2"

    - script: |
        # Guarantee all Astro/Vite cache directories AND their parents exist before Cache@2
        mkdir -p "$(Build.SourcesDirectory)/node_modules/.astro" "$(Build.SourcesDirectory)/.astro" "$(Agent.WorkFolder)/.astro-cache" "$(Build.SourcesDirectory)/node_modules/.vite"
        touch "$(Build.SourcesDirectory)/node_modules/.astro/.gitkeep" "$(Build.SourcesDirectory)/.astro/.gitkeep" "$(Agent.WorkFolder)/.astro-cache/.gitkeep" "$(Build.SourcesDirectory)/node_modules/.vite/.gitkeep"
      displayName: "Ensure cache directories exist and are non-empty (absolute paths) before Cache@2"

    - task: Cache@2
      displayName: Cache Astro build artifacts
      inputs:
        key: 'astro-build-v2 | "$(Agent.OS)" | $(Build.SourceBranchName) | $(Build.SourceVersion) | package.json | pnpm-lock.yaml'
        restoreKeys: |
          astro-build-v2 | "$(Agent.OS)" | $(Build.SourceBranchName)
          astro-build-v2 | "$(Agent.OS)"
          astro-build | "$(Agent.OS)"
        path: |
          $(Build.SourcesDirectory)/node_modules/.astro
          $(Build.SourcesDirectory)/.astro
          $(Agent.WorkFolder)/.astro-cache
          $(Build.SourcesDirectory)/node_modules/.vite
      continueOnError: false

    - script: |
        # Build with optimizations and cache configuration
        export NODE_OPTIONS="--max-old-space-size=4096"
        export ASTRO_CACHE_DIR="$(Agent.WorkFolder)/.astro-cache"
        export CI=true
        export ASTRO_TELEMETRY_DISABLED=1
        # Ensure cache directories exist and have proper permissions
        mkdir -p "$ASTRO_CACHE_DIR" node_modules/.vite node_modules/.astro .astro
        chmod -R 755 "$ASTRO_CACHE_DIR" node_modules/.vite node_modules/.astro .astro 2>/dev/null || true
        pnpm run build
      displayName: Build application

    - script: |
        # Preserve cache artifacts after build
        echo "Build completed. Cache directories status:"

        # Ensure all cache directories exist
        mkdir -p node_modules/.astro .astro "$ASTRO_CACHE_DIR" node_modules/.vite

        # Check and report directory contents
        if [ -d "node_modules/.astro" ]; then
          echo "node_modules/.astro/ contents:"
          ls -la node_modules/.astro/ || echo "Empty directory"
        fi

        if [ -d ".astro" ]; then
          echo ".astro/ contents:"
          ls -la .astro/ || echo "Empty directory"
        fi

        if [ -d "$ASTRO_CACHE_DIR" ]; then
          echo "ASTRO_CACHE_DIR contents:"
          ls -la "$ASTRO_CACHE_DIR" || echo "Empty directory"
        fi

        if [ -d "node_modules/.vite" ]; then
          echo "Vite cache contents:"
          ls -la node_modules/.vite || echo "Empty directory"
        fi

        # Ensure cache directories have at least placeholder files for next cache save
        touch node_modules/.astro/.gitkeep .astro/.gitkeep "$ASTRO_CACHE_DIR/.gitkeep" node_modules/.vite/.gitkeep

        echo "Cache preservation completed"
      displayName: Preserve cache artifacts
      env:
        ASTRO_CACHE_DIR: $(Agent.WorkFolder)/.astro-cache

- stage: DockerBuild
  displayName: Build Docker Image
  dependsOn: Build
  jobs:
  - job: BuildDockerImage
    displayName: Build and Push Docker Image
    pool:
      name: Default
      demands:
      - agent.os -equals Linux
      - docker
    steps:
    - script: |
        set -e
        echo "Installing Docker CLI in container..."
        sudo apt-get update -qq
        # Prefer docker.io for Debian/Ubuntu-based images
        sudo apt-get install -y docker.io

        # Verify Docker daemon is accessible
        if ! docker version >/dev/null 2>&1; then
          echo "‚ùå Docker daemon not accessible. Checking Docker socket..."
          ls -la /var/run/docker.sock || echo "Docker socket not found"
          echo "Docker service status:"
          systemctl status docker || echo "Cannot check Docker service status"
          exit 1
        fi

        echo "‚úÖ Docker CLI installed and daemon accessible"
        docker version
      displayName: "Install Docker CLI (host system)"
    - task: DownloadBuildArtifacts@0
      displayName: Download build artifacts
      inputs:
        buildType: "current"
        downloadType: "single"
        artifactName: "dist"
        downloadPath: "$(System.ArtifactsDirectory)"

    - script: |
        echo "Cleaning up old Docker containers before build..."
        if command -v docker &> /dev/null; then
          docker ps -a --filter "name=pixel" --format '{{.ID}} {{.Names}}' | while read id name; do
            echo "Removing container $name ($id)"
            docker rm -f "$id" || true
          done
        else
          echo "Docker not installed, skipping container cleanup."
        fi
      displayName: Clean up old Docker containers

    - script: |
        echo "Cleaning up disk space before Docker build..."
        # Check current disk usage
        df -h /

        # Clean up Docker system
        docker system prune -af --volumes || true

        # Clean package caches
        sudo apt-get clean || true
        sudo rm -rf /var/cache/apt/archives/* || true

        # Clean temporary files
        sudo rm -rf /tmp/* || true
        sudo rm -rf /var/tmp/* || true

        # Clean old log files
        sudo find /var/log -name "*.log" -type f -mtime +7 -delete || true

        # Check disk usage after cleanup
        df -h /

        DISK_USAGE=$(df / | awk 'END{print $(NF-1)}' | sed 's/%//')
        if [ "$DISK_USAGE" -gt 90 ]; then
          echo "##[warning]Disk usage is still high: ${DISK_USAGE}%"
        else
          echo "Disk usage after cleanup: ${DISK_USAGE}%"
        fi
      displayName: Clean up disk space

    - script: |
        set -e
        echo "Ensuring Azure CLI is available..."

        # Set environment variables to suppress warnings
        export PYTHONWARNINGS="ignore::FutureWarning"

        # Check if Azure CLI is already available
        if command -v az >/dev/null 2>&1; then
          echo "‚úÖ Azure CLI already available"
          az version
          exit 0
        fi

        echo "Azure CLI not found, installing via direct download..."

        # Install Azure CLI directly (most reliable method)
        curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash || {
          echo "‚ö†Ô∏è  Direct installation failed, trying alternative method..."

          # Fallback: Use pip with system Python
          python3 -m pip install --user azure-cli || {
            echo "‚ö†Ô∏è  Pip installation failed, trying conda if available..."

            # Last resort: Try conda
            if command -v conda >/dev/null 2>&1; then
              conda install -c conda-forge azure-cli -y --quiet || {
                echo "‚ùå All Azure CLI installation methods failed"
                echo "This may cause deployment issues, but pipeline will continue..."
                exit 0  # Don't fail the pipeline
              }
            else
              echo "‚ùå All Azure CLI installation methods failed"
              echo "This may cause deployment issues, but pipeline will continue..."
              exit 0  # Don't fail the pipeline
            fi
          }
        }

        # Verify installation
        if command -v az >/dev/null 2>&1; then
          echo "‚úÖ Azure CLI installed successfully"
          az version
        else
          echo "‚ö†Ô∏è  Azure CLI installation could not be verified"
        fi
      displayName: Ensure Azure CLI available (direct install)

    - task: AzureCLI@2
      displayName: Build and push Docker image
      inputs:
        azureSubscription: $(azureSubscription)
        scriptType: bash
        scriptLocation: inlineScript
        inlineScript: |
          echo "Looking for container registry 'pixelatedcr'"

          # Use the existing pixelatedcr registry
          ACR_NAME="pixelatedcr"

          # Verify it exists, create if it doesn't
          if ! az acr show --name "$ACR_NAME" --resource-group $(resourceGroupName) &>/dev/null; then
            echo "Container registry 'pixelatedcr' not found. Creating it..."
            az acr create \
              --name "$ACR_NAME" \
              --resource-group $(resourceGroupName) \
              --location $(azureLocation) \
              --sku Standard \
              --admin-enabled true

            echo "Created Container Registry: $ACR_NAME"
          else
            echo "Found existing Container Registry: $ACR_NAME"
          fi

          # Login to the container registry
          az acr login --name "$ACR_NAME"

          # Get the login server
          ACR_LOGIN_SERVER=$(az acr show --name "$ACR_NAME" --resource-group $(resourceGroupName) --query loginServer --output tsv)

          echo "Container Registry Login Server: $ACR_LOGIN_SERVER"

          # Copy build artifacts to current directory
          if [ -d "$(System.ArtifactsDirectory)/dist" ]; then
            cp -r $(System.ArtifactsDirectory)/dist ./
            echo "‚úÖ Copied build artifacts to current directory"
            echo "Build artifacts contents:"
            ls -la dist/ | head -10
          else
            echo "‚ùå Build artifacts not found at $(System.ArtifactsDirectory)/dist"
            echo "Available artifacts:"
            ls -la $(System.ArtifactsDirectory)/ || echo "No artifacts directory found"
            exit 1
          fi

          # Build and push Docker images with advanced multi-stage cache optimization
          echo "Building Docker image with multi-stage cache optimization..."

          # Use Dockerfile.azure if it exists, otherwise use Dockerfile
          DOCKERFILE="Dockerfile"
          if [ -f "Dockerfile.azure" ]; then
            DOCKERFILE="Dockerfile.azure"
            echo "‚úÖ Using Azure-specific Dockerfile: $DOCKERFILE"
          elif [ -f "Dockerfile" ]; then
            DOCKERFILE="Dockerfile"
            echo "‚úÖ Using default Dockerfile: $DOCKERFILE"
          else
            echo "‚ùå No Dockerfile found! Available files:"
            ls -la | grep -i docker || echo "No Docker-related files found"
            exit 1
          fi

          echo "Dockerfile contents preview:"
          head -20 "$DOCKERFILE"

          # Enable Docker BuildKit for advanced caching
          export DOCKER_BUILDKIT=1

          # Pull existing images for cache layers
          echo "Pulling existing images for cache optimization..."
          docker pull "$ACR_LOGIN_SERVER/$(imageName):latest" || echo "No latest image found, proceeding without cache"
          docker pull "$ACR_LOGIN_SERVER/$(imageName):cache-base" || echo "No base cache found"
          docker pull "$ACR_LOGIN_SERVER/$(imageName):cache-build" || echo "No build cache found"

          # Check if Dockerfile has multi-stage targets before attempting stage-specific builds
          if grep -q "FROM.*AS base" "$DOCKERFILE" 2>/dev/null; then
            echo "Multi-stage Dockerfile detected, building base stage for cache..."
            docker build \
              -f "$DOCKERFILE" \
              --target base \
              --cache-from "$ACR_LOGIN_SERVER/$(imageName):cache-base" \
              --cache-from "$ACR_LOGIN_SERVER/$(imageName):latest" \
              --build-arg BUILDKIT_INLINE_CACHE=1 \
              --build-arg NODE_VERSION=24 \
              --build-arg PNPM_VERSION=10.15.0 \
              -t "$ACR_LOGIN_SERVER/$(imageName):cache-base" \
              . || echo "Base stage build failed, continuing..."
          else
            echo "Single-stage Dockerfile detected, skipping base stage build"
          fi

          if grep -q "FROM.*AS build" "$DOCKERFILE" 2>/dev/null; then
            echo "Build stage detected, building for cache..."
            docker build \
              -f "$DOCKERFILE" \
              --target build \
              --cache-from "$ACR_LOGIN_SERVER/$(imageName):cache-base" \
              --cache-from "$ACR_LOGIN_SERVER/$(imageName):cache-build" \
              --cache-from "$ACR_LOGIN_SERVER/$(imageName):latest" \
              --build-arg BUILDKIT_INLINE_CACHE=1 \
              --build-arg NODE_VERSION=24 \
              --build-arg PNPM_VERSION=10.15.0 \
              -t "$ACR_LOGIN_SERVER/$(imageName):cache-build" \
              . || echo "Build stage build failed, continuing..."
          else
            echo "No build stage detected, skipping build stage cache"
          fi

          # Final production build with all cache layers
          echo "Building final production image..."
          docker build \
            -f "$DOCKERFILE" \
            --cache-from "$ACR_LOGIN_SERVER/$(imageName):cache-base" \
            --cache-from "$ACR_LOGIN_SERVER/$(imageName):cache-build" \
            --cache-from "$ACR_LOGIN_SERVER/$(imageName):latest" \
            --build-arg BUILDKIT_INLINE_CACHE=1 \
          --build-arg NODE_VERSION=24 \
          --build-arg PNPM_VERSION=10.15.0 \
          -t "$ACR_LOGIN_SERVER/$(imageName):$(dockerTag)" \
            -t "$ACR_LOGIN_SERVER/$(imageName):latest" \
            .

          echo "Pushing Docker images and cache layers..."
          # Push cache layers first for next build optimization
          docker push "$ACR_LOGIN_SERVER/$(imageName):cache-base" || echo "Base cache push failed"
          docker push "$ACR_LOGIN_SERVER/$(imageName):cache-build" || echo "Build cache push failed"

          # Push main images
          docker push "$ACR_LOGIN_SERVER/$(imageName):$(dockerTag)"
          docker push "$ACR_LOGIN_SERVER/$(imageName):latest"



          # Verify the push was successful
          echo "Verifying image push was successful..."
          sleep 5  # Give ACR a moment to process the push

          # Check if the image exists in the registry
          IMAGE_CHECK=$(az acr repository show-tags \
            --name "$ACR_NAME" \
            --repository "$(imageName)" \
            --query "[?contains(@, '$(dockerTag)')].length(@)" \
            --output tsv 2>/dev/null || echo "0")

          if [ "$IMAGE_CHECK" = "0" ]; then
            echo "‚ùå Failed to verify image push. Image $(imageName):$(dockerTag) not found in registry"
            echo "Available tags:"
            az acr repository show-tags \
              --name "$ACR_NAME" \
              --repository "$(imageName)" \
              --output table 2>/dev/null || echo "No tags found"
            exit 1
          else
            echo "‚úÖ Successfully verified image $(imageName):$(dockerTag) exists in registry"
          fi

          # Clean up local images to save space
          docker rmi "$ACR_LOGIN_SERVER/$(imageName):$(dockerTag)" || true
          docker rmi "$ACR_LOGIN_SERVER/$(imageName):latest" || true
          docker system prune -f

- stage: Deploy
  displayName: Deploy Container App
  dependsOn:
  - Build
  - DockerBuild
  condition: and(succeeded(), or(eq(variables['Build.SourceBranchName'], 'master'), eq(variables['Build.SourceBranchName'], 'main')))
  jobs:
  - deployment: ContainerAppDeployment
    displayName: Deploy to Container Apps
    environment:
      name: azure-production
    pool:
      name: Default
    strategy:
      runOnce:
        deploy:
          steps:
          - script: |
              set -eo pipefail
              # Ensure Node.js (LTS 24.x) is available for any Node-based steps
              echo "Installing Node.js (LTS 24.x) for container agent..."
              sudo apt-get update -qq && sudo apt-get install -y curl ca-certificates
              curl -fsSL https://deb.nodesource.com/setup_24.x | sudo -E bash -
              sudo apt-get install -y nodejs
              node --version

              echo "Ensuring Azure CLI is available..."

              # Set environment variables to suppress warnings
              export PYTHONWARNINGS="ignore::FutureWarning"

              # Check if Azure CLI is already available
              if command -v az >/dev/null 2>&1; then
                echo "‚úÖ Azure CLI already available"
                az version
                exit 0
              fi

              echo "Azure CLI not found, installing via direct download..."

              # Install Azure CLI directly (most reliable method)
              curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash || {
                echo "‚ö†Ô∏è  Direct installation failed, trying alternative method..."

                # Fallback: Use pip with system Python
                python3 -m pip install --user azure-cli || {
                  echo "‚ö†Ô∏è  Pip installation failed, trying conda if available..."

                  # Last resort: Try conda
                  if command -v conda >/dev/null 2>&1; then
                    conda install -c conda-forge azure-cli -y --quiet || {
                      echo "‚ùå All Azure CLI installation methods failed"
                      echo "This may cause deployment issues, but pipeline will continue..."
                      exit 0  # Don't fail the pipeline
                    }
                  else
                    echo "‚ùå All Azure CLI installation methods failed"
                    echo "This may cause deployment issues, but pipeline will continue..."
                    exit 0  # Don't fail the pipeline
                  fi
                }
              }

              # Verify installation
              if command -v az >/dev/null 2>&1; then
                echo "‚úÖ Azure CLI installed successfully"
                az version
              else
                echo "‚ö†Ô∏è  Azure CLI installation could not be verified"
              fi
            displayName: Ensure Azure CLI available (direct install)

          - task: AzureCLI@2
            displayName: Deploy Container App
            inputs:
              azureSubscription: $(azureSubscription)
              scriptType: bash
              scriptLocation: inlineScript
              inlineScript: |
                echo "Deploying Container App: $(containerAppName)"
                CONTAINER_APP_NAME="$(containerAppName)"

                # Check if the container app already exists
                if az containerapp show --name "$CONTAINER_APP_NAME" --resource-group $(resourceGroupName) >/dev/null 2>&1; then
                  echo "Container App exists, updating with new image..."
                  UPDATE_MODE="update"
                else
                  echo "Container App doesn't exist, creating new one..."
                  UPDATE_MODE="create"
                fi

                # Use the existing pixelatedcr registry
                ACR_NAME="pixelatedcr"

                # Verify it exists
                if ! az acr show --name "$ACR_NAME" --resource-group $(resourceGroupName) &>/dev/null; then
                  echo "‚ùå Container Registry 'pixelatedcr' not found in resource group"
                  echo "Available registries:"
                  az acr list --resource-group $(resourceGroupName) --query "[].name" --output table
                  exit 1
                fi

                ACR_LOGIN_SERVER=$(az acr show --name "$ACR_NAME" --resource-group $(resourceGroupName) --query loginServer --output tsv)
                echo "Using Container Registry: $ACR_NAME ($ACR_LOGIN_SERVER)"

                # Enable admin user on ACR if not already enabled
                echo "Ensuring ACR admin user is enabled..."
                az acr update --name "$ACR_NAME" --admin-enabled true

                # Get ACR admin credentials
                ACR_USERNAME=$(az acr.credential show --name "$ACR_NAME" --query username --output tsv)
                ACR_PASSWORD=$(az acr.credential show --name "$ACR_NAME" --query passwords[0].value --output tsv)
                echo "Retrieved ACR credentials for user: $ACR_USERNAME"

                # Verify the Docker image exists before deployment
                echo "Verifying Docker image exists: $ACR_LOGIN_SERVER/$(imageName):$(dockerTag)"
                IMAGE_EXISTS=$(az acr.repository show-tags \
                  --name "$ACR_NAME" \
                  --repository "$(imageName)" \
                  --query "[?contains(@, '$(dockerTag)')].length(@)" \
                  --output tsv)

                if [ -z "$IMAGE_EXISTS" ] || [ "$IMAGE_EXISTS" = "0" ]; then
                  echo "‚ùå Docker image $(imageName):$(dockerTag) not found in registry"
                  echo "Available tags for $(imageName):"
                  az acr.repository show-tags \
                    --name "$ACR_NAME" \
                    --repository "$(imageName)" \
                    --output table || echo "No tags found or repository doesn't exist"

                  echo "Available repositories:"
                  az acr.repository list \
                    --name "$ACR_NAME" \
                    --output table

                  echo "Attempting to use 'latest' tag as fallback..."
                  DOCKER_IMAGE_TAG="latest"
                else
                  echo "‚úÖ Docker image $(imageName):$(dockerTag) found in registry"
                  DOCKER_IMAGE_TAG="$(dockerTag)"
                fi

                # Find Container App Environment
                APP_ENV_NAME=$(az containerapp env list \
                  --resource-group $(resourceGroupName) \
                  --query "[?starts_with(name, 'pixel-env')].name | [0]" \
                  --output tsv)

                if [ -z "$APP_ENV_NAME" ]; then
                  echo "No Container App Environment found. Creating one..."
                  # Generate unique suffix for resources
                  UNIQUE_SUFFIX=$(echo -n "$(resourceGroupName)-$(environment)" | sha256sum | cut -c1-8)
                  APP_ENV_NAME="pixel-env-${UNIQUE_SUFFIX}"

                  az containerapp env create \
                    --name "$APP_ENV_NAME" \
                    --resource-group $(resourceGroupName) \
                    --location $(azureLocation) \
                    --only-show-errors

                  if [ $? -ne 0 ]; then
                    echo "‚ùå Failed to create Container App Environment"
                    exit 1
                  fi
                  echo "‚úÖ Created Container App Environment: $APP_ENV_NAME"
                else
                  echo "Found Container App Environment: $APP_ENV_NAME"
                fi

                echo "Container App operation mode: $UPDATE_MODE"
                echo "Using Docker image: $ACR_LOGIN_SERVER/$(imageName):$DOCKER_IMAGE_TAG"

                if [ "$UPDATE_MODE" = "update" ]; then
                  echo "Updating existing Container App: $CONTAINER_APP_NAME"

                  az containerapp update \
                    --name "$CONTAINER_APP_NAME" \
                    --resource-group $(resourceGroupName) \
                    --image "$ACR_LOGIN_SERVER/$(imageName):$DOCKER_IMAGE_TAG" \
                    --cpu 1.0 \
                    --memory 2Gi \
                    --min-replicas 1 \
                    --max-replicas 10 \
                    --set-env-vars \
                      "BUILD_ID=$(dockerTag)" \
                      "NODE_ENV=production" \
                      "PORT=4321" \
                      "PUBLIC_CLERK_PUBLISHABLE_KEY=$(CLERK_PUBLISHABLE_KEY)" \
                      "CLERK_SECRET_KEY=$(CLERK_SECRET_KEY)" \
                    --only-show-errors

                  if [ $? -eq 0 ]; then
                    echo "‚úÖ Container App updated successfully"
                  else
                    echo "‚ùå Container App update failed"
                    exit 1
                  fi
                else
                  echo "Creating new Container App: $CONTAINER_APP_NAME"

                  az containerapp create \
                    --name "$CONTAINER_APP_NAME" \
                    --resource-group $(resourceGroupName) \
                    --environment "$APP_ENV_NAME" \
                    --image "$ACR_LOGIN_SERVER/$(imageName):$DOCKER_IMAGE_TAG" \
                    --target-port 4321 \
                    --ingress 'external' \
                    --registry-server "$ACR_LOGIN_SERVER" \
                    --registry-username "$ACR_USERNAME" \
                    --registry-password "$ACR_PASSWORD" \
                    --cpu 1.0 \
                    --memory 2Gi \
                    --min-replicas 1 \
                    --max-replicas 10 \
                    --env-vars \
                      "BUILD_ID=$(dockerTag)" \
                      "NODE_ENV=production" \
                      "PORT=4321" \
                      "PUBLIC_CLERK_PUBLISHABLE_KEY=$(CLERK_PUBLISHABLE_KEY)" \
                      "CLERK_SECRET_KEY=$(CLERK_SECRET_KEY)" \
                    --only-show-errors

                  if [ $? -eq 0 ]; then
                    echo "‚úÖ Container App created successfully"
                  else
                    echo "‚ùå Container App creation failed"
                    exit 1
                  fi
                fi

                # Configure custom domain if specified
                CUSTOM_DOMAIN="$(customDomain)"
                if [ ! -z "$CUSTOM_DOMAIN" ] && [ "$CUSTOM_DOMAIN" != "" ]; then
                  echo "Configuring custom domain: $CUSTOM_DOMAIN"

                  # Add custom domain to the Container App
                  az containerapp hostname add \
                    --hostname "$CUSTOM_DOMAIN" \
                    --name "$CONTAINER_APP_NAME" \
                    --resource-group $(resourceGroupName) \
                    --only-show-errors || {
                    echo "‚ö†Ô∏è  Failed to add custom domain $CUSTOM_DOMAIN"
                    echo "Make sure:"
                    echo "1. DNS CNAME record points $CUSTOM_DOMAIN to the Container App FQDN"
                    echo "2. Domain ownership is verified"
                    echo "3. You have necessary permissions"
                  }

                  # Create managed certificate for the custom domain
                  echo "Creating managed certificate for $CUSTOM_DOMAIN..."
                  az containerapp env certificate create \
                    --name "${CUSTOM_DOMAIN//./-}-cert" \
                    --environment "$APP_ENV_NAME" \
                    --resource-group $(resourceGroupName) \
                    --hostname "$CUSTOM_DOMAIN" \
                    --validation-method CNAME \
                    --only-show-errors || {
                    echo "‚ö†Ô∏è  Failed to create managed certificate for $CUSTOM_DOMAIN"
                    echo "You may need to manually create and bind an SSL certificate"
                  }

                  # Bind the certificate to the hostname
                  CERT_ID=$(az containerapp env certificate list \
                    --environment "$APP_ENV_NAME" \
                    --resource-group $(resourceGroupName) \
                    --query "[?properties.subjectName=='$CUSTOM_DOMAIN'].id | [0]" \
                    --output tsv)

                  if [ ! -z "$CERT_ID" ]; then
                    echo "Binding certificate to hostname..."
                    az containerapp hostname bind \
                      --hostname "$CUSTOM_DOMAIN" \
                      --name "$CONTAINER_APP_NAME" \
                      --resource-group $(resourceGroupName) \
                      --certificate "$CERT_ID" \
                      --only-show-errors || {
                      echo "‚ö†Ô∏è  Failed to bind certificate to $CUSTOM_DOMAIN"
                    }
                  fi

                  echo "‚úÖ Custom domain configuration completed for: $CUSTOM_DOMAIN"
                else
                  echo "No custom domain specified, using default Container App URL"
                fi

                # Get and display the Container App URL
                APP_URL=$(az containerapp show \
                  --name "$CONTAINER_APP_NAME" \
                  --resource-group $(resourceGroupName) \
                  --query properties.configuration.ingress.fqdn \
                  --output tsv)

                if [ ! -z "$APP_URL" ]; then
                  echo "üöÄ Container App deployed to: https://$APP_URL"
                  echo "##vso[task.setvariable variable=containerAppUrl]https://$APP_URL"

                  # Also show custom domain if configured
                  CUSTOM_DOMAIN="$(customDomain)"
                  if [ ! -z "$CUSTOM_DOMAIN" ] && [ "$CUSTOM_DOMAIN" != "" ]; then
                    echo "üåê Custom domain: https://$CUSTOM_DOMAIN"
                  fi
                else
                  echo "‚ö†Ô∏è  Could not retrieve Container App URL"
                fi

- stage: DeployAppService
  displayName: Deploy to App Service
  dependsOn: DockerBuild
  condition: and(succeeded(), or(eq(variables['Build.SourceBranchName'], 'master'), eq(variables['Build.SourceBranchName'], 'main')))
  jobs:
  - deployment: AppServiceDeployment
    displayName: Deploy to App Service
    environment:
      name: azure-production
    pool:
      name: Default
    strategy:
      runOnce:
        deploy:
          steps:
          - script: |
              set -eo pipefail
              echo "Ensuring Azure CLI is available..."
              export PYTHONWARNINGS="ignore::FutureWarning"
              if ! command -v az >/dev/null 2>&1; then
                echo "Azure CLI not found; bootstrapping via uv..."
                if ! command -v uv >/dev/null 2>&1; then
                  curl -LsSf https://astral.sh/uv/install.sh | sh
                  export PATH="$HOME/.local/bin:$PATH"
                fi
                uv venv "$HOME/azure-cli-env"
                "$HOME/azure-cli-env/bin/python" -m pip install --upgrade pip
                "$HOME/azure-cli-env/bin/pip" install "azure-cli==2.73.0"
                echo "##vso[task.prependpath]$HOME/azure-cli-env/bin"
              fi
              az version
            displayName: Ensure Azure CLI available (uv fallback)

          - task: AzureCLI@2
            displayName: Deploy to App Service
            inputs:
              azureSubscription: $(azureSubscription)
              scriptType: bash
              scriptLocation: inlineScript
              inlineScript: |
                echo "Deploying to App Service: $(appServiceName)"
                APP_SERVICE_NAME="$(appServiceName)"

                # Use the existing pixelatedcr registry
                ACR_NAME="pixelatedcr"
                ACR_LOGIN_SERVER=$(az acr show --name "$ACR_NAME" --resource-group $(resourceGroupName) --query loginServer --output tsv)

                echo "Using Container Registry: $ACR_NAME ($ACR_LOGIN_SERVER)"
                echo "Using Docker image: $ACR_LOGIN_SERVER/$(imageName):$(dockerTag)"

                # Get ACR credentials first
                ACR_USERNAME=$(az acr credential show --name "$ACR_NAME" --query username --output tsv)
                ACR_PASSWORD=$(az acr credential show --name "$ACR_NAME" --query passwords[0].value --output tsv)

                echo "Using ACR credentials: $ACR_USERNAME"

                # Configure App Service for container deployment using new syntax
                echo "Configuring App Service container settings..."
                az webapp config container set \
                  --name "$APP_SERVICE_NAME" \
                  --resource-group $(resourceGroupName) \
                  --container-image-name "$ACR_LOGIN_SERVER/$(imageName):$(dockerTag)" \
                  --container-registry-url "https://$ACR_LOGIN_SERVER" \
                  --container-registry-user "$ACR_USERNAME" \
                  --container-registry-password "$ACR_PASSWORD"

                # Configure App Service app settings
                echo "Configuring App Service environment variables..."
                az webapp config appsettings set \
                  --name "$APP_SERVICE_NAME" \
                  --resource-group $(resourceGroupName) \
                  --settings \
                    BUILD_ID=$(dockerTag) \
                    NODE_ENV=production \
                    PORT=4321 \
                    WEBSITES_PORT=4321 \
                    PUBLIC_CLERK_PUBLISHABLE_KEY="$(CLERK_PUBLISHABLE_KEY)" \
                    CLERK_SECRET_KEY="$(CLERK_SECRET_KEY)" \
                    WEBSITES_ENABLE_APP_SERVICE_STORAGE=false

                # Restart App Service to pick up new container
                echo "Restarting App Service to deploy new container..."
                az webapp restart \
                  --name "$APP_SERVICE_NAME" \
                  --resource-group $(resourceGroupName)

                # Get App Service URL
                APP_URL=$(az webapp show \
                  --name "$APP_SERVICE_NAME" \
                  --resource-group $(resourceGroupName) \
                  --query defaultHostName \
                  --output tsv)

                if [ ! -z "$APP_URL" ]; then
                  echo "üöÄ App Service deployed to: https://$APP_URL"
                  echo "üåê Custom domain: https://$(customDomain)"
                  echo "##vso[task.setvariable variable=appServiceUrl]https://$APP_URL"
                else
                  echo "‚ö†Ô∏è  Could not retrieve App Service URL"
                fi

- stage: PostDeploymentTests
  displayName: Post Deployment Tests
  dependsOn:
  - Deploy
  - DeployAppService
  condition: succeeded()
  jobs:
  - job: HealthCheck
    displayName: Health Check Both Deployments
    pool:
      name: Default
    steps:
    - script: |
        # Verify Azure CLI is available in container
        echo "Verifying Azure CLI availability..."
        az version
      displayName: Verify Azure CLI

    - task: AzureCLI@2
      displayName: Health Check - Container App
      inputs:
        azureSubscription: $(azureSubscription)
        scriptType: bash
        scriptLocation: inlineScript
        inlineScript: |
          CONTAINER_APP_NAME="$(containerAppName)"
          RESOURCE_GROUP="$(resourceGroupName)"

          # Check Container App health
          echo "Checking health of Container App: $CONTAINER_APP_NAME"
          APP_HEALTH=$(az containerapp show \
            --name "$CONTAINER_APP_NAME" \
            --resource-group "$RESOURCE_GROUP" \
            --query "properties.provisioningState" \
            --output tsv)

          if [ "$APP_HEALTH" != "Succeeded" ]; then
            echo "‚ùå Container App is not healthy: $APP_HEALTH"
            exit 1
          fi

          echo "‚úÖ Container App is healthy"

          # Optionally, check specific app endpoints for response
          APP_URL=$(az containerapp show \
            --name "$CONTAINER_APP_NAME" \
            --resource-group "$RESOURCE_GROUP" \
            --query "properties.configuration.ingress.fqdn" \
            --output tsv)

          if [ ! -z "$APP_URL" ]; then
            echo "Checking HTTP response from app URL: https://$APP_URL"
            HTTP_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" "https://$APP_URL")

            if [ "$HTTP_RESPONSE" -ne 200 ]; then
              echo "‚ùå Health check failed: Received HTTP $HTTP_RESPONSE"
              exit 1
            fi

            echo "‚úÖ Health check passed: Received HTTP $HTTP_RESPONSE"
          else
            echo "‚ö†Ô∏è  App URL not found, skipping HTTP health check"
          fi
      env:
        AZURE_CLI_DISABLE_CONNECTION_VERIFICATION: "1"

- stage: Cleanup
  displayName: Cleanup Old Deployments
  dependsOn: PostDeploymentTests
  condition: succeeded()
  jobs:
  - job: CleanupOldApps
    displayName: Clean Up Old Container Apps Only
    pool:
      name: Default
    steps:
    - script: |
        # Verify Azure CLI is available in container
        echo "Verifying Azure CLI availability..."
        az version
      displayName: Verify Azure CLI

    - task: AzureCLI@2
      displayName: Clean up old deployments
      inputs:
        azureSubscription: $(azureSubscription)
        scriptType: bash
        scriptLocation: inlineScript
        inlineScript: |
          # Clean up old container apps if they exist
          echo "Cleaning up old container apps..."
          OLD_APPS=$(az containerapp list \
            --resource-group $(resourceGroupName) \
            --query "[?starts_with(name, 'pixel-') && name != '$(containerAppName)'].name" \
            --output tsv)

          if [ ! -z "$OLD_APPS" ]; then
            echo "Found old container apps to clean up:"
            echo "$OLD_APPS"
            echo "$OLD_APPS" | while read app_name; do
              if [ ! -z "$app_name" ]; then
                echo "Deleting old Container App: $app_name"
                az containerapp delete \
                  --name "$app_name" \
                  --resource-group $(resourceGroupName) \
                  --yes \
                  --only-show-errors || {
                  echo "‚ö†Ô∏è  Failed to delete $app_name, continuing..."
                }
              fi
            done
          else
            echo "No old container apps found to clean up"
          fi

          # Clean up old Docker images in ACR
          echo "Cleaning up old Docker images in Container Registry..."
          ACR_NAME="pixelatedcr"

          # Get all tags for the image
          ALL_TAGS=$(az acr.repository show-tags \
            --name "$ACR_NAME" \
            --repository "$(imageName)" \
            --output tsv 2>/dev/null | sort -V || echo "")

          if [ ! -z "$ALL_TAGS" ]; then
            TAG_COUNT=$(echo "$ALL_TAGS" | grep -c "^" || echo "0")
            echo "Found $TAG_COUNT image tags in registry"

            if [ "$TAG_COUNT" -gt 10 ]; then
              TAGS_TO_DELETE=$((TAG_COUNT - 10))
              echo "Keeping only the 10 most recent image tags (including cache layers), deleting $TAGS_TO_DELETE oldest"

              echo "$ALL_TAGS" | grep -v "latest" | grep -v "cache-" | head -n $TAGS_TO_DELETE | while read tag; do
                if [ ! -z "$tag" ] && [ "$tag" != "$(dockerTag)" ]; then
                  echo "Deleting old image tag: $(imageName):$tag"
                  az acr.repository delete \
                    --name "$ACR_NAME" \
                    --image "$(imageName):$tag" \
                    --yes \
                    --only-show-errors || {
                    echo "‚ö†Ô∏è  Failed to delete image tag $tag, but continuing..."
                  }
                fi
              done
            else
              echo "‚úÖ No image cleanup needed - only $TAG_COUNT tags exist (keeping cache layers for optimization)"
            fi
          else
            echo "No image tags found for cleanup"
          fi

          echo "üßπ Cleanup completed!"
          echo "================================="
          echo "You can now access your production site at: https://$(customDomain)"
