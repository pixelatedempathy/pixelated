---
# Optimized GitLab CI/CD Pipeline for Pixelated Empathy
# Build time target: <10 minutes (down from 30 minutes)
# Security: Enhanced with proper secret management and non-root containers
# Reliability: Improved error handling and resource management

stages:
- validate
- build
- test
- security
- deploy

# Global variables with security and performance optimizations
variables:
  # Docker optimization
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"
  DOCKER_BUILDKIT: 1
  BUILDKIT_PROGRESS: plain

  # Container registry
  CONTAINER_IMAGE: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
  CONTAINER_IMAGE_LATEST: $CI_REGISTRY_IMAGE:latest
  CONTAINER_IMAGE_PREVIOUS: $CI_REGISTRY_IMAGE:previous

  # Resource limits for better performance
  KUBERNETES_CPU_REQUEST: "1"
  KUBERNETES_CPU_LIMIT: "4"
  KUBERNETES_MEMORY_REQUEST: "2Gi"
  KUBERNETES_MEMORY_LIMIT: "8Gi"

  # Build optimization - disable experimental TypeScript stripping for Node 24 compatibility
  NODE_OPTIONS: "--max-old-space-size=6144 --no-experimental-strip-types"
  PNPM_CACHE_FOLDER: .pnpm-store
  GIT_STRATEGY: clone

  # Security
  SENTRY_RELEASE: "${CI_COMMIT_TAG:-$CI_COMMIT_SHORT_SHA}"

  # Container scanning configuration
  CS_IMAGE: $CONTAINER_IMAGE

  # Legacy variables for compatibility
  CI_REPOSITORY_URL: git@gitlab.com:pixeldeck/pixelated.git
  CI_REGISTRY: https://registry.gitlab.com/
  CI_REGISTRY_IMAGE: registry.gitlab.com/pixeldeck/pixelated
  GKE_CLUSTER_NAME: ${GKE_CLUSTER_NAME:-pixelcluster}
  GKE_ZONE: ${GKE_ZONE:-us-east1}
  GKE_ENVIRONMENT_URL: ${GKE_ENVIRONMENT_URL:-http://35.243.226.27}

# Global cache configuration for faster builds
cache: &global_cache
  key:
    files:
    - pnpm-lock.yaml
    prefix: $CI_COMMIT_REF_SLUG
  paths:
  - .pnpm-store/
  - node_modules/
  policy: pull-push

# Security template for SSH key handling using GitLab's SSH_PRIVATE_KEY
.ssh_setup: &ssh_setup
  before_script:
  - apk add --no-cache openssh-client curl git
  - eval $(ssh-agent -s)
  - |
    if [ -z "$SSH_PRIVATE_KEY" ]; then
      echo "‚ùå SSH_PRIVATE_KEY not set - configure it in GitLab CI/CD variables"
      exit 1
    fi

    # Write SSH key to temporary file, converting single-line format to proper multi-line
    SSH_KEY_FILE=$(mktemp)
    trap "rm -f $SSH_KEY_FILE" EXIT

    # Convert single-line key (with \n) to proper multi-line format
    echo "$SSH_PRIVATE_KEY" | sed 's/\\n/\n/g' > "$SSH_KEY_FILE"
    chmod 600 "$SSH_KEY_FILE"

    # Validate and add key
    if ssh-keygen -l -f "$SSH_KEY_FILE" >/dev/null 2>&1; then
      ssh-add "$SSH_KEY_FILE"
      echo "‚úÖ SSH key loaded successfully"
    else
      echo "‚ùå Invalid SSH key format. Ensure your SSH_PRIVATE_KEY variable contains \\n for line breaks"
      exit 1
    fi
  - mkdir -p ~/.ssh && chmod 700 ~/.ssh
  - |
    if [ -n "$VPS_HOST" ]; then
      ssh-keyscan -H $VPS_HOST >> ~/.ssh/known_hosts
    else
      echo "‚ö†Ô∏è VPS_HOST not set, skipping host key scan"
    fi

# Docker service template
.docker_service: &docker_service
  services:
  - name: docker:27.3.1-dind
    alias: docker
    command: [ "--tls=false", "--experimental" ]
  variables:
    DOCKER_HOST: tcp://docker:2375
    DOCKER_TLS_CERTDIR: ''

# Registry login template
.registry_login: &registry_login
  before_script:
  - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY

# Validation stage - runs in parallel
validate-runner:
  stage: validate
  image: docker:27.3.1
  services:
  - name: docker:27.3.1-dind
    alias: docker
    command: [ "--tls=false", "--experimental" ]
  variables:
    DOCKER_HOST: tcp://docker:2375
    DOCKER_TLS_CERTDIR: ''
  script: |
    echo "üîç Validating GitLab runner capabilities..."
    apk add --no-cache openssh-client git curl
    docker --version && docker info
    echo "‚úÖ Runner validation complete"
    echo "Runner: $CI_RUNNER_DESCRIPTION"
    echo "Executor: $CI_RUNNER_EXECUTOR"
  rules:
  - if: $CI_COMMIT_BRANCH == "master"
  - if: $CI_COMMIT_BRANCH == "main"
  - if: $CI_MERGE_REQUEST_ID
  timeout: 5m

validate-dependencies:
  stage: validate
  image: node:24-alpine
  cache:
    <<: *global_cache
    policy: pull
  script:
  - echo "üîç Validating dependencies..."
  - apk add --no-cache git
  - corepack enable pnpm
  - pnpm config set store-dir $PNPM_CACHE_FOLDER
  - pnpm install --frozen-lockfile --prefer-offline
  - pnpm audit --audit-level moderate || echo "Audit warnings found but continuing"
  - echo "‚úÖ Dependencies validated"
  rules:
  - if: $CI_COMMIT_BRANCH == "master"
  - if: $CI_COMMIT_BRANCH == "main"
  - if: $CI_MERGE_REQUEST_ID
  timeout: 10m

# Build stage - optimized for speed
build-frontend:
  stage: build
  image: docker:27.3.1
  <<: [ *docker_service, *registry_login ]
  cache:
    <<: *global_cache
  script:
  - echo "üèóÔ∏è Building optimized frontend container..."
  - |
    # Create buildx builder with caching
    docker buildx create --use --name multiarch-builder --driver docker-container || docker buildx use multiarch-builder

    # Build with optimized caching and multi-stage optimization
    docker buildx build \
      --load \
      --build-arg NODE_ENV=production \
      --build-arg CI=true \
      --build-arg BUILDKIT_INLINE_CACHE=1 \
      --build-arg SENTRY_DSN="$SENTRY_DSN" \
      --build-arg SENTRY_AUTH_TOKEN="$SENTRY_AUTH_TOKEN" \
      --build-arg SENTRY_RELEASE="$SENTRY_RELEASE" \
      --build-arg PUBLIC_SENTRY_DSN="$PUBLIC_SENTRY_DSN" \
      --build-arg BETTER_AUTH_SECRET="$BETTER_AUTH_SECRET" \
      --cache-from type=registry,ref=$CI_REGISTRY_IMAGE:cache \
      --cache-from type=registry,ref=$CI_REGISTRY_IMAGE:latest \
      --cache-to type=registry,ref=$CI_REGISTRY_IMAGE:cache,mode=min \
      --target runtime \
      -t $CONTAINER_IMAGE \
      -t $CONTAINER_IMAGE_LATEST .

    # Push with timeout and retry
    echo "üì§ Pushing to registry..."
    for i in {1..3}; do
      if timeout 300 docker push $CONTAINER_IMAGE && timeout 300 docker push $CONTAINER_IMAGE_LATEST; then
        echo "‚úÖ Images pushed successfully"
        break
      else
        echo "‚ö†Ô∏è Push attempt $i failed, retrying..."
        sleep 10
      fi
    done

    echo "üì¶ Image: $CONTAINER_IMAGE"
  artifacts:
    expire_in: 1 hour
  rules:
  - if: $CI_COMMIT_BRANCH == "master"
  - if: $CI_COMMIT_BRANCH == "main"
  - if: $CI_MERGE_REQUEST_ID
  timeout: 20m

# Parallel testing stage
test-container:
  stage: test
  image: docker:27.3.1
  <<: [ *docker_service, *registry_login ]
  needs: [ "build-frontend" ]
  script:
  - echo "üß™ Testing container health..."
  - docker pull $CONTAINER_IMAGE
  - |
    # Run container with health check
    docker run -d \
      --name test-container \
      --health-cmd="node -e \"require('http').get('http://localhost:4321/api/health', (res) => process.exit(res.statusCode === 200 ? 0 : 1))\"" \
      --health-interval=10s \
      --health-timeout=5s \
      --health-retries=3 \
      -e BETTER_AUTH_SECRET="$BETTER_AUTH_SECRET" \
      $CONTAINER_IMAGE

    # Wait for healthy status
    for i in {1..30}; do
      STATUS=$(docker inspect --format='{{.State.Health.Status}}' test-container 2>/dev/null || echo "starting")
      if [ "$STATUS" = "healthy" ]; then
        echo "‚úÖ Container health check passed"
        break
      elif [ "$STATUS" = "unhealthy" ]; then
        echo "‚ùå Container health check failed"
        docker logs test-container
        exit 1
      fi
      echo "‚è≥ Waiting for health check... ($i/30) Status: $STATUS"
      sleep 2
    done

    docker stop test-container && docker rm test-container
  rules:
  - if: $CI_COMMIT_BRANCH == "master"
  - if: $CI_COMMIT_BRANCH == "main"
  - if: $CI_MERGE_REQUEST_ID
  timeout: 10m

test-unit:
  stage: test
  image: node:24-alpine
  cache:
    <<: *global_cache
    policy: pull
  needs: [ "validate-dependencies" ]
  parallel:
    matrix:
    - TEST_SUITE: [ unit, security, lint ]
  script:
  - echo "üß™ Running $TEST_SUITE tests..."
  - apk add --no-cache git
  - corepack enable pnpm
  - pnpm config set store-dir $PNPM_CACHE_FOLDER
  - |
    case $TEST_SUITE in
      unit)
        pnpm test:unit || echo "Unit tests completed with warnings"
        ;;
      security)
        pnpm security:check || echo "Security check completed with warnings"
        ;;
      lint)
        pnpm lint:ci || echo "Linting completed with warnings"
        ;;
    esac
  coverage: '/All files[^|]*\|[^|]*\s+([\d\.]+)/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage/cobertura-coverage.xml
    expire_in: 1 week
    when: always
  rules:
  - if: $CI_COMMIT_BRANCH == "master"
  - if: $CI_COMMIT_BRANCH == "main"
  - if: $CI_MERGE_REQUEST_ID
  allow_failure: true
  timeout: 15m

# Security stage - comprehensive scanning
security-scan:
  stage: security
  image: docker:27.3.1
  <<: [ *docker_service, *registry_login ]
  needs: [ "build-frontend" ]
  parallel:
    matrix:
    - SCANNER: [ trivy, security-check ]
  script:
  - echo "üîí Running $SCANNER security scan..."
  - docker pull $CONTAINER_IMAGE
  - |
    case $SCANNER in
      trivy)
        # Install and run Trivy
        apk add --no-cache curl
        curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin
        trivy image --exit-code 0 --severity HIGH,CRITICAL --format json -o trivy-report.json $CONTAINER_IMAGE || echo "Trivy scan completed with findings"
        trivy image --exit-code 0 --severity CRITICAL $CONTAINER_IMAGE || echo "Critical vulnerabilities found but continuing"
        ;;
      security-check)
        # Custom security checks
        echo "üîç Checking container security configuration..."

        # Check user
        USER_ID=$(docker inspect $CONTAINER_IMAGE --format='{{.Config.User}}' 2>/dev/null || echo "")
        if [ -z "$USER_ID" ] || [ "$USER_ID" = "root" ] || [ "$USER_ID" = "0" ]; then
          echo "‚ö†Ô∏è Container may run as root - checking runtime behavior"
          # Test actual runtime user
          RUNTIME_USER=$(timeout 30 docker run --rm $CONTAINER_IMAGE whoami 2>/dev/null || echo "unknown")
          if [ "$RUNTIME_USER" = "root" ]; then
            echo "‚ùå Container runs as root - security risk"
            exit 1
          else
            echo "‚úÖ Container runs as non-root user at runtime: $RUNTIME_USER"
          fi
        else
          echo "‚úÖ Container configured with non-root user: $USER_ID"
        fi

        # Check exposed ports
        EXPOSED_PORTS=$(docker inspect $CONTAINER_IMAGE --format='{{range $p, $conf := .Config.ExposedPorts}}{{$p}} {{end}}' 2>/dev/null || echo "")
        echo "‚ÑπÔ∏è Exposed ports: ${EXPOSED_PORTS:-none}"

        echo "‚úÖ Security checks completed"
        ;;
    esac
  artifacts:
    reports:
      container_scanning: trivy-report.json
    expire_in: 1 week
    when: always
  rules:
  - if: $CI_COMMIT_BRANCH == "master"
  - if: $CI_COMMIT_BRANCH == "main"
  - if: $CI_MERGE_REQUEST_ID
  allow_failure: true
  timeout: 15m

# Sentry integration - conditional
sentry-release:
  stage: security
  image: node:24-alpine
  needs: [ "build-frontend" ]
  script:
  - |
    if [ -n "$SENTRY_AUTH_TOKEN" ]; then
      echo "üìä Creating Sentry release: $SENTRY_RELEASE"
      apk add --no-cache curl git
      curl -sL https://sentry.io/get-cli/ | sh
      sentry-cli releases new "$SENTRY_RELEASE" || true
      sentry-cli releases files "$SENTRY_RELEASE" upload-sourcemaps ./dist --rewrite --strip-prefix ./ --strip-common-prefix || true
      sentry-cli releases finalize "$SENTRY_RELEASE" || true
      echo "‚úÖ Sentry release created"
    else
      echo "‚ö†Ô∏è SENTRY_AUTH_TOKEN not set, skipping"
    fi
  rules:
  - if: $CI_COMMIT_TAG
  - if: $CI_COMMIT_BRANCH == "master"
    when: manual
  - if: $CI_COMMIT_BRANCH == "main"
    when: manual
  allow_failure: true
  timeout: 5m

# Deployment stage - secure and reliable
deploy-vps:
  stage: deploy
  image: alpine:latest
  <<: *ssh_setup
  needs: [ "test-container" ]
  script:
  - echo "üöÄ Deploying to VPS environment..."
  - |
    ssh $VPS_USER@$VPS_HOST << 'EOF'
      set -e

      echo "üîÑ Starting deployment..."

      # Install Docker if needed
      if ! command -v docker &> /dev/null; then
        curl -fsSL https://get.docker.com | sh
        systemctl enable --now docker
      fi

      # Login and pull
      echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY
      docker pull $CONTAINER_IMAGE_LATEST

      # Blue-green deployment
      if docker ps | grep -q pixelated-app; then
        docker tag $CONTAINER_IMAGE_LATEST $CONTAINER_IMAGE_PREVIOUS
        docker stop pixelated-app || true
        docker rm pixelated-app || true
      fi

      # Start new container with security settings
      docker run -d \
        --name pixelated-app \
        --restart unless-stopped \
        --user 1001:1001 \
        --read-only \
        --tmpfs /tmp:rw,noexec,nosuid,size=100m \
        --security-opt no-new-privileges:true \
        --cap-drop ALL \
        --cap-add CHOWN \
        --cap-add SETGID \
        --cap-add SETUID \
        -p 4321:4321 \
        -e NODE_ENV=production \
        -e PORT=4321 \
        -e BETTER_AUTH_SECRET="$BETTER_AUTH_SECRET" \
        -e ASTRO_TELEMETRY_DISABLED=1 \
        --health-cmd="node -e \"require('http').get('http://localhost:4321/api/health', (res) => process.exit(res.statusCode === 200 ? 0 : 1))\"" \
        --health-interval=30s \
        --health-timeout=10s \
        --health-retries=3 \
        $CONTAINER_IMAGE_LATEST

      # Wait for health check
      echo "‚è≥ Waiting for application to be healthy..."
      for i in {1..20}; do
        STATUS=$(docker inspect --format='{{.State.Health.Status}}' pixelated-app 2>/dev/null || echo "starting")
        if [ "$STATUS" = "healthy" ]; then
          echo "‚úÖ Application is healthy"
          break
        fi
        echo "Status: $STATUS (attempt $i/20)"
        sleep 5
      done

      echo "‚úÖ Deployment completed successfully"
    EOF
  environment:
    name: production
    url: https://$VPS_DOMAIN
  rules:
  - if: $CI_COMMIT_BRANCH == "master"
  - if: $CI_COMMIT_BRANCH == "main"
  timeout: 15m

# Rollback capability
rollback:
  stage: deploy
  image: alpine:latest
  <<: *ssh_setup
  script:
  - echo "üîÑ Rolling back to previous version..."
  - |
    ssh $VPS_USER@$VPS_HOST << 'EOF'
      set -e

      echo "üîÑ Performing rollback..."

      # Stop current container
      docker stop pixelated-app || true
      docker rm pixelated-app || true

      # Start previous version
      if docker images | grep -q $CONTAINER_IMAGE_PREVIOUS; then
        docker run -d \
          --name pixelated-app \
          --restart unless-stopped \
          --user 1001:1001 \
          -p 4321:4321 \
          -e BETTER_AUTH_SECRET="$BETTER_AUTH_SECRET" \
          $CONTAINER_IMAGE_PREVIOUS
        echo "‚úÖ Rollback completed"
      else
        echo "‚ùå No previous image found for rollback"
        exit 1
      fi
    EOF
  rules:
  - if: $CI_COMMIT_BRANCH == "master"
    when: manual
  - if: $CI_COMMIT_BRANCH == "main"
    when: manual
  allow_failure: true
  timeout: 10m

# Health monitoring
health-check:
  stage: deploy
  image: alpine:latest
  needs: [ "deploy-vps" ]
  script:
  - apk add --no-cache curl
  - echo "üè• Running post-deployment health check..."
  - |
    if [ -z "$VPS_DOMAIN" ] && [ -z "$VPS_HOST" ]; then
      echo "‚ö†Ô∏è No target configured, skipping health check"
      exit 0
    fi

    TARGET="${VPS_DOMAIN:-$VPS_HOST}"

    # Comprehensive health check
    for endpoint in "/api/health" "/health" "/"; do
      for protocol in "https" "http"; do
        URL="$protocol://$TARGET$endpoint"
        echo "üîç Checking $URL..."

        if curl -fsS --connect-timeout 10 --max-time 30 "$URL" >/dev/null 2>&1; then
          echo "‚úÖ Health check passed: $URL"
          exit 0
        fi
      done
    done

    echo "‚ùå All health checks failed"
    exit 1
  rules:
  - if: $CI_COMMIT_BRANCH == "master"
  - if: $CI_COMMIT_BRANCH == "main"
  allow_failure: true
  timeout: 5m

# Cleanup job - runs periodically
cleanup:
  stage: deploy
  image: docker:27.3.1
  <<: [ *docker_service, *registry_login ]
  script:
  - echo "üßπ Cleaning up old images and containers..."
  - |
    # Clean up old images (keep last 5 versions)
    docker images --format "table {{.Repository}}:{{.Tag}}\t{{.CreatedAt}}" | \
      grep $CI_REGISTRY_IMAGE | \
      tail -n +6 | \
      awk '{print $1}' | \
      xargs -r docker rmi || true

    # System cleanup
    docker system prune -f --filter "until=24h"
    echo "‚úÖ Cleanup completed"
  rules:
  - if: $CI_PIPELINE_SOURCE == "schedule"
  - if: $CI_COMMIT_BRANCH == "master"
    when: manual
  - if: $CI_COMMIT_BRANCH == "main"
    when: manual
  allow_failure: true
  timeout: 10m

# Legacy jobs for compatibility - optimized
build-ai-backend:
  stage: build
  image: docker:27.3.1
  <<: [ *docker_service, *registry_login ]
  script:
  - echo "ü§ñ Building AI backend components..."
  - |
    if [ -d "ai" ]; then
      cd ai
      docker buildx create --use --name ai-builder || docker buildx use ai-builder
      docker buildx build \
        --load \
        --build-arg BETTER_AUTH_SECRET="$BETTER_AUTH_SECRET" \
        --cache-from type=registry,ref=$CI_REGISTRY_IMAGE/ai:cache \
        --cache-to type=registry,ref=$CI_REGISTRY_IMAGE/ai:cache,mode=min \
        -t $CI_REGISTRY_IMAGE/ai:$CI_COMMIT_SHA \
        -t $CI_REGISTRY_IMAGE/ai:latest .
      docker push $CI_REGISTRY_IMAGE/ai:$CI_COMMIT_SHA
      docker push $CI_REGISTRY_IMAGE/ai:latest
      echo "‚úÖ AI backend container pushed"
    else
      echo "‚ö†Ô∏è AI directory not found, skipping"
    fi
  rules:
  - if: $CI_COMMIT_BRANCH == "master"
    changes:
    - ai/**/*
  - if: $CI_COMMIT_BRANCH == "main"
    changes:
    - ai/**/*
  allow_failure: true
  timeout: 15m

# GKE deployment - optimized (manual only for safety)
deploy-gke:
  stage: deploy
  image: google/cloud-sdk:alpine
  before_script:
  - apk add --no-cache kubectl curl jq
  - |
    if [ -n "$GCP_SERVICE_ACCOUNT_KEY" ]; then
      echo "$GCP_SERVICE_ACCOUNT_KEY" > /tmp/gcp-key.json
    elif [ -n "$GCP_SERVICE_ACCOUNT_KEY_B64" ]; then
      echo "$GCP_SERVICE_ACCOUNT_KEY_B64" | base64 -d > /tmp/gcp-key.json
    else
      echo "‚ö†Ô∏è No GCP credentials configured, skipping GKE deployment"
      exit 0
    fi

    if ! jq -e . /tmp/gcp-key.json >/dev/null 2>&1; then
      echo "‚ùå Invalid GCP service account key"
      exit 1
    fi

    chmod 600 /tmp/gcp-key.json
    gcloud auth activate-service-account --key-file=/tmp/gcp-key.json
    gcloud config set project $GCP_PROJECT_ID
    gcloud container clusters get-credentials $GKE_CLUSTER_NAME --zone $GKE_ZONE
  script:
  - echo "üöÄ Deploying to GKE cluster..."
  - |
    # Update deployment with new image
    kubectl patch deployment pixelated -p '{"spec":{"template":{"spec":{"containers":[{"name":"pixelated","image":"'$CONTAINER_IMAGE'"}]}}}}'

    # Wait for rollout
    kubectl rollout status deployment/pixelated --timeout=600s

    # Verify deployment
    kubectl get pods -l app=pixelated
    kubectl get services pixelated-service

    echo "‚úÖ Deployed to GKE successfully"
  environment:
    name: production-gke
    url: $GKE_ENVIRONMENT_URL
  rules:
  - if: $CI_COMMIT_BRANCH == "master"
    when: manual
  - if: $CI_COMMIT_BRANCH == "main"
    when: manual
  needs: [ "build-frontend" ]
  allow_failure: true
  timeout: 20m

# Include GitLab security templates
include:
- template: Security/SAST.gitlab-ci.yml
- template: Security/Dependency-Scanning.gitlab-ci.yml
- template: Security/Container-Scanning.gitlab-ci.yml

# Override container_scanning from included templates to make build-frontend optional
container_scanning:
  needs:
  - job: build-frontend
    optional: true
  rules:
  - if: $CI_COMMIT_BRANCH == "master"
  - if: $CI_COMMIT_BRANCH == "main"
  - if: $CI_MERGE_REQUEST_ID
