# Logstash pipeline configuration for Pixelated Empathy
input {
  beats {
    port => 5044
    ssl => false
  }

  tcp {
    port => 5000
    codec => json_lines
  }

  udp {
    port => 5000
    codec => json_lines
  }

  # Application logs from bias detection service
  file {
    path => "/usr/share/logstash/logs/bias_detection.log"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/.sincedb_bias_detection"
    codec => multiline {
      pattern => "^%{TIMESTAMP_ISO8601}"
      negate => true
      what => "previous"
    }
  }

  # Celery worker logs
  file {
    path => "/usr/share/logstash/logs/celery*.log"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/.sincedb_celery"
    codec => multiline {
      pattern => "^\\[%{TIMESTAMP_ISO8601}"
      negate => true
      what => "previous"
    }
  }
}

filter {
  # Parse JSON logs
  json {
    source => "message"
    target => "parsed_json"
    remove_field => ["message"]
  }

  # Extract timestamp
  date {
    match => ["timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss.SSS", "yyyy-MM-dd HH:mm:ss"]
    target => "@timestamp"
    remove_field => ["timestamp"]
  }

  # Add service information
  mutate {
    add_field => {
      "service" => "%{[parsed_json][service]}"
      "level" => "%{[parsed_json][level]}"
      "module" => "%{[parsed_json][module]}"
      "message" => "%{[parsed_json][message]}"
    }
    remove_field => ["parsed_json"]
  }

  # Parse bias detection specific logs
  if [service] == "bias_detection" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:log_timestamp} - %{WORD:logger_name} - %{WORD:log_level} - %{GREEDYDATA:log_message}"
      }
      overwrite => ["message"]
    }

    # Extract session information from bias analysis logs
    if [log_message] =~ /session.*analysis|bias.*score/ {
      grok {
        match => {
          "log_message" => ".*session (?<session_id>[a-f0-9-]+).*bias_score.*(?<bias_score>[0-9.]+).*"
        }
      }
    }
  }

  # Parse Celery worker logs
  if [module] =~ /celery/ {
    grok {
      match => {
        "message" => "\\[%{TIMESTAMP_ISO8601:celery_timestamp}\\]\\s*\\[%{WORD:log_level}/%{WORD:process_name}\\]\\s*%{GREEDYDATA:celery_message}"
      }
    }

    # Extract task information
    if [celery_message] =~ /task.*started|task.*completed|task.*failed/ {
      grok {
        match => {
          "celery_message" => ".*task (?<task_name>[a-zA-Z_.]+)\\((?<task_id>[a-f0-9-]+)\\).*"
        }
      }
    }
  }

  # Add geo information for IP addresses
  if [client_ip] {
    geoip {
      source => "client_ip"
      target => "geo"
    }
  }

  # Add user agent parsing
  if [user_agent] {
    useragent {
      source => "user_agent"
      target => "user_agent_parsed"
    }
  }

  # Anonymize sensitive data
  mutate {
    # Remove or hash sensitive fields
    remove_field => ["password", "token", "secret", "key"]
    # Anonymize IP addresses (keep first two octets)
    if [client_ip] {
      gsub => ["client_ip", "\.\d+\.\d+$", ".0.0"]
    }
  }
}

output {
  # Main Elasticsearch output
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "pixelated-%{+YYYY.MM.dd}"
    document_type => "_doc"
    template => "/usr/share/logstash/config/elasticsearch-template.json"
    template_name => "pixelated-logs"
    template_overwrite => true
  }

  # Separate index for bias detection events
  if [service] == "bias_detection" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "pixelated-bias-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
  }

  # Separate index for Celery tasks
  if [module] =~ /celery/ {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "pixelated-celery-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
  }

  # Debug output (remove in production)
  if "_debug" in [tags] {
    stdout {
      codec => rubydebug
    }
  }
}